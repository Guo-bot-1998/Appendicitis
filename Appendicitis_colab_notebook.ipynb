{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guo-bot-1998/Appendicitis/blob/master/Appendicitis_colab_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coYrDLBnCbwQ"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q4kBLfXWRg7N",
        "outputId": "34db2adb-475d-4b68-cd63-208856475786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.12)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.10/dist-packages (0.9.20)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kora) (7.34.0)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from kora) (1.5.29)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore->kora) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->kora) (23.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kora) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kora) (0.2.12)\n",
            "Requirement already satisfied: fake_useragent in /usr/local/lib/python3.10/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install tqdm\n",
        "!pip install kora\n",
        "!pip install fake_useragent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bQ4w8h2LkY0g"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import re\n",
        "import json\n",
        "import tqdm\n",
        "import timm\n",
        "import gdown\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 存取"
      ],
      "metadata": {
        "id": "Oc3DYvY3WsL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_data2(shift=0, termi=10, dropFalse=0.85, dropPos=0)\\\n",
        " -> tuple[torch.tensor, torch.tensor, list[tuple[str, int]]]:\n",
        "  \"\"\"Reading data in \"datadir\" and process them.\n",
        "  Taking care of memory efficiency\"\n",
        "\n",
        "  Args:\n",
        "    shift: 從第幾個開始讀取\n",
        "    termi: 讀取幾個\n",
        "    dropFalse: 被刪除的有闌尾炎的張數比例\n",
        "    dropPos: 被刪除的有闌尾炎的張數比例\n",
        "\n",
        "  Returns:\n",
        "    images: 输出的图像数据\n",
        "    labels: 输出的标签数据\n",
        "    scans_info: 每個scan的檔名和切片數(原本nii檔所包含的數量)\n",
        "  \"\"\"\n",
        "\n",
        "  labels_ = read_label(labelpath)\n",
        "\n",
        "  if labels_.index.name != 'id':\n",
        "    labels_.set_index('id', inplace=True)\n",
        "\n",
        "  #裁減過的圖片放在Cropped_[範圍]的資料夾下,用路徑名稱判斷資料使否裁減過\n",
        "  cropmatch = re.search(r'Cropped', datadir)\n",
        "  if not cropmatch:\n",
        "    print(\"讀取未切片的資料夾\")\n",
        "    xlim, ylim, zlim = [0,512], [0,512], [0,None]\n",
        "  else:\n",
        "    #範圍 = xstart-xend_ystart-yend_zstart-zend\n",
        "    ismatch = re.search(r'(\\d+-\\d+)_(\\d+-\\d+)_(\\d+-\\d+)', string)\n",
        "    if ismatch:\n",
        "      dimens = ismatch.group(0)\n",
        "      labelidx = dimens.split('_')\n",
        "      xlim = [int(idx) for idx in labelidx[0].split('-')]\n",
        "      ylim = [int(idx) for idx in labelidx[1].split('-')]\n",
        "      zlim = [int(idx) for idx in labelidx[2].split('-')]\n",
        "      print(f\"{xlim=}\\n{ylim=}\\n{zlim=}\")\n",
        "      if xlim[0] >= xlim[1] or ylim[0] >= ylim[1] or zlim[0] >= zlim[1]:\n",
        "        print(\"切片格式不正确\")\n",
        "        return\n",
        "    else:\n",
        "      print(\"切片格式不正确\")\n",
        "      return\n",
        "\n",
        "\n",
        "  filelist = os.listdir(datadir)\n",
        "  filelist = filelist[shift:shift+termi]\n",
        "  scans_info = []\n",
        "\n",
        "  # preallocated\n",
        "  if not cropmatch:\n",
        "    selecteds = [labels_.loc[labels_.index.str.startswith(afile.strip('.nii.gz')+'_')] for afile in filelist]\n",
        "    numcuts = [len(selected) for selected in selecteds]\n",
        "    numcuts = sum(numcuts)\n",
        "  else:\n",
        "    numcuts = (zlim[1]-zlim[0]) * len(filelist)\n",
        "  images = torch.zeros(numcuts,1, ylim[-1]-ylim[0],xlim[-1]-xlim[0])\n",
        "  labels = -torch.ones(numcuts)\n",
        "  nimgs = 0\n",
        "  nprocess = 0\n",
        "\n",
        "  for key in filelist:\n",
        "    file_path = os.path.join(datadir, key)\n",
        "    key = key.strip('.nii.gz')\n",
        "    scan  = labels_.loc[labels_.index.str.startswith(key+'_')]\n",
        "\n",
        "    value = nib.load(file_path).get_fdata()\n",
        "    scans_info.append((key, value.shape[2]))\n",
        "\n",
        "\n",
        "    label_t = torch.tensor(scan['label'][zlim[0]:zlim[-1]])\n",
        "    image_t = torch.from_numpy(value).float().permute(2, 0, 1).unsqueeze(1)\n",
        "\n",
        "    #有幾筆不是512x512\n",
        "    if (not cropmatch) and (image_t.shape[2] != 512 or image_t.shape[3] != 512):\n",
        "      image_t = cropping(image_t)\n",
        "\n",
        "    image_t, label_t = remove_false_images(image_t, label_t, dropFalse)\n",
        "    image_t, label_t = remove_positive_images(image_t, label_t, dropPos)\n",
        "\n",
        "    n_new = len(label_t)\n",
        "\n",
        "    images[nimgs:nimgs+n_new] = image_t\n",
        "    labels[nimgs:nimgs+n_new] = label_t\n",
        "    nimgs += len(label_t)\n",
        "    print(f\"Process {nprocess}: {key} finished...\")\n",
        "    nprocess += 1\n",
        "\n",
        "  print(f\"read {len(scans_info)} scans\")\n",
        "\n",
        "  return images, labels.float(), scans_info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_model(model, modelname=\"\", dirname=\"\", root=os.path.realpath(\"/content/drive/MyDrive/AOCR2024/params\")):\n",
        "\n",
        "  if not model:\n",
        "    print(\"not given model\")\n",
        "    return\n",
        "\n",
        "  if not os.path.exists(root):\n",
        "    print(f\"{root} not exists!\")\n",
        "    return\n",
        "\n",
        "  print(f\"model will be saved under {root}\")\n",
        "\n",
        "\n",
        "  if not modelname:\n",
        "    modelname = input(\"請輸入模型儲存的檔名:\")\n",
        "  if not dirname:\n",
        "    dirname = input(\"請輸入模型儲存的資料夾:\")\n",
        "\n",
        "  filename = f\"{root}/{dirname}/{modelname}\"\n",
        "\n",
        "  if not os.path.exists(os.path.dirname(filename)):\n",
        "    os.mkdir(os.path.dirname(filename))\n",
        "\n",
        "  if os.path.isfile(filename+'.pth'):\n",
        "      print(f\"{filename}.pth exist.\")\n",
        "  else:\n",
        "      torch.save(model.state_dict(), f'{filename}.pth')\n",
        "\n",
        "  return filename\n",
        "\n",
        "\n",
        "\n",
        "def read_label(excel_path) -> pd.DataFrame:\n",
        "  \"\"\"Reads a csv file containing ground-truth.\n",
        "    The csv file should have two columns: 'id' and 'label'.\n",
        "  \"\"\"\n",
        "  with open(excel_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "    df.set_index('id', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def write_error(logpath, e, nprocess):\n",
        "  # with open(logpath, 'a') as f:\n",
        "    # f.write(f\"{nprocess:} error occured: {e}\\n\") ##! may stuck the program!!\n",
        "  print(f\"{nprocess:} error occured: {e}\\n\")\n",
        "\n",
        "\n",
        "def read_submission(excel_path) -> pd.DataFrame:\n",
        "  \"\"\"Reads a csv file containing submission file.\n",
        "    The csv file should follow the format given by Kaggle.\n",
        "  \"\"\"\n",
        "  with open(excel_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "    df.set_index('id', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KLs_ItZEW0F1"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 列印結果"
      ],
      "metadata": {
        "id": "Fnggb7x7X8Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confusion(guess, truth):\n",
        "  right = guess == truth\n",
        "  wrong = np.logical_not(right)\n",
        "  TP = np.sum(np.logical_and(right, truth == np.ones(right.shape)))\n",
        "  TN = np.sum(np.logical_and(right, truth == np.zeros(right.shape)))\n",
        "  FN = np.sum(np.logical_and(wrong, truth == np.ones(wrong.shape)))\n",
        "  FP = np.sum(np.logical_and(wrong, truth == np.zeros(wrong.shape)))\n",
        "  return (TP,FP,FN,TN)\n",
        "\n",
        "\n",
        "\n",
        "def print_results(prediction, labels):\n",
        "  if torch.is_tensor(prediction):\n",
        "    prediction = prediction.cpu().numpy()\n",
        "  if torch.is_tensor(labels):\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "  TP,FP,FN,TN = get_confusion(prediction, labels)\n",
        "  print(f\"\\n\\\n",
        "      真實值\\n\\\n",
        "  預  +-----+-----+\\n\\\n",
        "  測| TP: {TP}| FP: {FP}|\\n\\\n",
        "  值| FN: {FN}| TN: {TN}|\\n\\\n",
        "      +-----+-----+ \\n\")\n",
        "\n",
        "  recall = TP/(TP + FN)\n",
        "  precision = TP/(TP + FP)\n",
        "  recall = 0 if np.isnan(recall) else recall.item()\n",
        "  precision = 0 if np.isnan(precision) else precision.item()\n",
        "  F1 = 0 if recall + precision == 0 else  (2*recall*precision/(recall+precision))\n",
        "\n",
        "  print(f\"{recall=}\\n{precision=}\\n{F1=}\\n\")"
      ],
      "metadata": {
        "id": "1gFEpWQ-X7nc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 數據處理\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UsmaGmRwWmxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argumenting(images, labels, n=5):\n",
        "  \"\"\"\n",
        "  數據增強。\n",
        "  在images裡面把所有有闌尾炎的cut複製給定次數，並\n",
        "  插入回images的隨機位置裡面\n",
        "\n",
        "  Args:\n",
        "    images: 输入的图像数据\n",
        "    labels: 输入的标签数据\n",
        "    n: 每个样本複製多少次\n",
        "\n",
        "  Returns:\n",
        "    增強后的图像数据和标签数据\n",
        "  \"\"\"\n",
        "  where = (labels == True).nonzero(as_tuple=True)[0]\n",
        "  bad_images = images[where]\n",
        "\n",
        "  rep_imgs = bad_images.repeat(n, 1, 1, 1)\n",
        "  rep_labels = torch.ones(rep_imgs.shape[0], dtype=labels.dtype)\n",
        "\n",
        "  # import pdb\n",
        "  # pdb.set_trace()\n",
        "  # 隨機插入argumented圖片\n",
        "  nimg = images.shape[0]\n",
        "  rnd_pos = torch.randint(0, nimg, (rep_imgs.shape[0],))\n",
        "  images = torch.cat((images, rep_imgs), dim=0)\n",
        "  images = images[torch.argsort(torch.cat((torch.arange(nimg), rnd_pos)))]\n",
        "\n",
        "  # 對應對置插入標籤\n",
        "  labels = torch.cat((labels, rep_labels), dim=0)\n",
        "  labels = labels[torch.argsort(torch.cat((torch.arange(nimg), rnd_pos)))]\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "def remove_false_images(images, labels, ratio):\n",
        "    \"\"\"\n",
        "    隨機在images裡面移除一定比例的無闌尾炎cut\n",
        "\n",
        "    Args:\n",
        "      images: 输入的图像数据\n",
        "      labels: 输入的标签数据\n",
        "      ratio: 移除的比例\n",
        "\n",
        "    Returns:\n",
        "      移除后的图像数据和标签数据\n",
        "    \"\"\"\n",
        "    # 找出 labels == 0 的索引\n",
        "    where_false = (labels == 0).nonzero(as_tuple=True)[0]\n",
        "    mask = torch.ones(len(images), dtype=torch.bool)\n",
        "    indices_filter = torch.randperm(len(where_false))[:int(len(where_false)*ratio)]\n",
        "    mask[where_false[indices_filter]] = False\n",
        "    images = images[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def remove_positive_images(images, labels, ratio):\n",
        "    # 找出 labels == 1 的索引\n",
        "    where_positive = (labels == 1).nonzero(as_tuple=True)[0]\n",
        "    mask = torch.ones(len(images), dtype=torch.bool)\n",
        "    indices_filter = torch.randperm(len(where_positive))[:int(len(where_positive)*ratio)]\n",
        "    mask[where_positive[indices_filter]] = False\n",
        "    images = images[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "6nLNS0uRWl5X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 其他"
      ],
      "metadata": {
        "id": "BdwzEjFhbR4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7dmJYugUB_3w"
      },
      "outputs": [],
      "source": [
        "\n",
        "def count_zero(images):\n",
        "  count = 0\n",
        "  for image in images:\n",
        "    if not torch.any(image):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "def cropping(image):\n",
        "  if image.shape[2] != 512:\n",
        "    start = (image.shape[2] - 512) // 2\n",
        "    end = start + 512\n",
        "    image = image[:, :, start:end, :]\n",
        "\n",
        "  if image.shape[3] != 512:\n",
        "    start = (image.shape[3] - 512) // 2\n",
        "    end = start + 512\n",
        "    image = image[:, :, :, start:end]\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def custom_sort_key(val):\n",
        "    parts = val.split('_')\n",
        "    if len(parts) == 2 and parts[1].isdigit():\n",
        "        return (parts[0], int(parts[1]))\n",
        "    return (parts[0], -1)  # 使沒有_(數字)的id排最前面\n",
        "\n",
        "\n",
        "def isgpu():\n",
        "    \"\"\"檢查是否有 CUDA 支持的 GPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"GPU is available\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        # raise(\"GPU not available\")\n",
        "    return device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ud4x-GeICQxw"
      },
      "outputs": [],
      "source": [
        "device = isgpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV66iCZmCrBJ"
      },
      "source": [
        "# 掛載\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bKUXzQOdBRFQ",
        "outputId": "c937ff47-f27a-42dc-970e-6abe48bcd406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "5qbhdYNrGRxf",
        "outputId": "0ab7e9f3-f6f0-4659-bc2a-18346ac02f5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use service account to access googledrive"
      ],
      "metadata": {
        "id": "CwxsNMJG9E-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import googleapiclient.discovery\n",
        "from google.auth.exceptions import TransportError\n",
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "DriveAPIcredentials = r\"/content/drive/MyDrive/AOCR2024/creds/appendicitis-407217-c2f141040794.json\"\n",
        "credentials = Credentials.from_service_account_file(DriveAPIcredentials,scopes=[\"https://www.googleapis.com/auth/drive\"])\n",
        "drive_service = googleapiclient.discovery.build('drive', 'v3', credentials=credentials)"
      ],
      "metadata": {
        "id": "p46LlGr13crr"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 資料下載"
      ],
      "metadata": {
        "id": "3OZg-WX2NgQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_rootdir = \"/content/drive/MyDrive/AOCR2024\"\n",
        "labelpath = '/content/drive/MyDrive/AOCR2024/TrainValid_ground_truth.csv'\n",
        "\n",
        "datadir =\"Cropped_60-316_150-406_11-71/Train_Valid_Image_cropped\"\n",
        "if not os.path.exists('/content/' +datadir):\n",
        "  os.mkdir(datadir)\n"
      ],
      "metadata": {
        "id": "dzzWlsmwlPCZ"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kora.xattr import get_id\n",
        "\n",
        "files_on_drive = os.listdir(drive_rootdir+'/'+datadir)\n",
        "files_in_localdir = os.listdir(f\"/content/{datadir}\")\n",
        "files_to_download = [f for f in files_on_drive if f not in files_in_localdir]\n",
        "files = [(filename, get_id(f'{drive_rootdir}/{datadir}/{filename}')) for filename in files_to_download]\n",
        "\n",
        "\n",
        "for idx, (name, file_id) in enumerate(files):\n",
        "\n",
        "  if not file_id:\n",
        "    print(f\"未找到文件: {name}\")\n",
        "    continue\n",
        "\n",
        "  # 下载文件\n",
        "  request = drive_service.files().get_media(fileId=file_id)\n",
        "  fh = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(fh, request)\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "    status, done = downloader.next_chunk()\n",
        "    # print(f\"下载 {name} 进度: {int(status.progress() * 100)}%\")\n",
        "\n",
        "  # 将文件内容写入本地文件\n",
        "  local_file_path = os.path.join('/content', datadir, name)\n",
        "\n",
        "  with open(local_file_path, 'wb') as f:\n",
        "    fh.seek(0)\n",
        "    f.write(fh.read())\n",
        "\n",
        "  print(f\"{idx+1}/{len(files)}: {name} downloaded\")\n"
      ],
      "metadata": {
        "id": "vFY-Mi1k6uS8",
        "outputId": "16b8eb5f-1522-4383-8a66-9868f2995c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/920: Zx1882493D839CC3171D0FEA7AE764BB5BC308D707E75CCB60.nii.gz downloaded\n",
            "2/920: Zx1950A84DEF7878F0CDEE2AE1E07365E7C7F651215ED72155.nii.gz downloaded\n",
            "3/920: Zx1950A84DEF7878F0254E551A842C621B4740CE91E85CE8E2.nii.gz downloaded\n",
            "4/920: Zx1950A84DEF7878F043E3BB7A5D65E310BC050172FCA7CC14.nii.gz downloaded\n",
            "5/920: Zx19216E0DC2CA308E80238A39CC927E17148D86C6DF471355.nii.gz downloaded\n",
            "6/920: Zx1977ADC4FB423A510927DE5147FA1581381604AC0BB7E825.nii.gz downloaded\n",
            "7/920: Zx1950A84DEF7878F0FA4F817AEE5D56DF2534349D8C94B8F5.nii.gz downloaded\n",
            "8/920: Zx1950A84DEF7878F0F9E32AF9F820CA049C5880BA46C37601.nii.gz downloaded\n",
            "9/920: Zx19DC911CF61B42EE4F9E967F39224A9297426E7C6AC03D8E.nii.gz downloaded\n",
            "10/920: Zx19DC911CF61B42EEA04DF8635951103535C9FB92AD779276.nii.gz downloaded\n",
            "11/920: Zx1A3FF9BBC87A0A6379CA804FA7025BE5E55D98B90E6E911E.nii.gz downloaded\n",
            "12/920: Zx19A878BE9D7FCDD564CF0D0630D0E05F305D03B734E6FBE5.nii.gz downloaded\n",
            "13/920: Zx1A8AFCB885E0D8BC44A0ED9AEF59DD90D90777A8345747EE.nii.gz downloaded\n",
            "14/920: Zx1A447D96D387B7C45053917769DF2A154E9A765A87D51A24.nii.gz downloaded\n",
            "15/920: Zx1A5E6FEE5BA94F6D9C91E1BBACAE6959AB96EB6442A0524B.nii.gz downloaded\n",
            "16/920: Zx1AC280D33D45A2973879438429EB6E09CB3DF1914B26DED8.nii.gz downloaded\n",
            "17/920: Zx1BBA21D9DA37F2D063D4A85F624E8D72C0410728E334B442.nii.gz downloaded\n",
            "18/920: Zx1BDF4C967678080E6779C2713B10F3B23CE3C1CC7F2CC8BB.nii.gz downloaded\n",
            "19/920: Zx1C6B814369828D2A1FE29B8B7CD4D21752A8CB1AE56781F5.nii.gz downloaded\n",
            "20/920: Zx1ECC8B15EE2388642B2C05331250EEB951BE580304D38622.nii.gz downloaded\n",
            "21/920: Zx1D4DA6EB30F0E21BAE9B15E262721240DDC420DD988AAC16.nii.gz downloaded\n",
            "22/920: Zx1E550FA95B8A7552A06CE65E3BEED1EE034D46B71AC2990F.nii.gz downloaded\n",
            "23/920: Zx1F0C08B15A2FA4B85694E240248D208FBA9CDCFA1B19D3E5.nii.gz downloaded\n",
            "24/920: Zx1F0951EDF2B31E5E932707FD021961BFCF8586E917ABD120.nii.gz downloaded\n",
            "25/920: Zx1ED66EE4F0492C4C63EED347F5480C328DED4C1955880614.nii.gz downloaded\n",
            "26/920: Zx2030E3E34625286F57D63B10F1912D4A18F991C22F6463A1.nii.gz downloaded\n",
            "27/920: Zx1F83D85BC2A7A55A165937332E32D7646399FC21D7283669.nii.gz downloaded\n",
            "28/920: Zx1F2D6E616335D5D7A26B93C9CBB01658781603DFF3B46DF8.nii.gz downloaded\n",
            "29/920: Zx2030E3E34625286FAA000B1D4CFF2D07BD489B513C82E9A8.nii.gz downloaded\n",
            "30/920: Zx208D824934941221A20E8F9C315A6AF45B61E20DB5B3F4E5.nii.gz downloaded\n",
            "31/920: Zx2030E3E34625286FA6745CAFEF3F4CD81DEDDFA875C5EC23.nii.gz downloaded\n",
            "32/920: Zx20BDA35C14C29E61E035F264496CD4F4F97D288082512F40.nii.gz downloaded\n",
            "33/920: Zx215A14F9057233B70538C32D1748F817319662FD34E6690A.nii.gz downloaded\n",
            "34/920: Zx213F87C44A60B71BFE117EB0EB9A5870E0CEB9197701FF60.nii.gz downloaded\n",
            "35/920: Zx226CB151F5DE15D8C8C6E3F3EE8BC533BDBE65DE1A805731.nii.gz downloaded\n",
            "36/920: Zx220A8CBFA565CB8498E6FB702C7E03B920F2361EE7B62A6D.nii.gz downloaded\n",
            "37/920: Zx239BC1FBE61089C9B2368A86E36BDF3136292547D9C0EBC4.nii.gz downloaded\n",
            "38/920: Zx23BEFE24BACE6B249C37C240B74348796802474012995344.nii.gz downloaded\n",
            "39/920: Zx22D56AA7E544151923FF1A90F02F59919EC170C85187649E.nii.gz downloaded\n",
            "40/920: Zx23BEFE24BACE6B24798B7B8ADA70E5DE0151270247B6EB07.nii.gz downloaded\n",
            "41/920: Zx23CE39ADA19715437B08F04B4F1E962B9E854E1DE01B814F.nii.gz downloaded\n",
            "42/920: Zx23F8F44ED97A93B2C3487F13DBE296C7A694804866EFF350.nii.gz downloaded\n",
            "43/920: Zx246E98149CE2B848DD11D93B1DAC382E56997966B5FB4B1A.nii.gz downloaded\n",
            "44/920: Zx25DFF1358FA299AFC3345BEE8BCD80031225017D9F4DD365.nii.gz downloaded\n",
            "45/920: Zx24711EE075325408C49B564C1D646B2F1A6BE15A31716D85.nii.gz downloaded\n",
            "46/920: Zx25DFF1358FA299AFF037CA3B98580B73B25B4E2B3B4172F3.nii.gz downloaded\n",
            "47/920: Zx25DFF1358FA299AFD313E29BFC17C150096D2B97BDB7E2ED.nii.gz downloaded\n",
            "48/920: Zx247C48E8B7D1EABBA1DEF5CD4AC1D8E8ACAFA8C759A85107.nii.gz downloaded\n",
            "49/920: Zx2727C103B14E93A07709A14282274DD35B6A23AA6127CB0B.nii.gz downloaded\n",
            "50/920: Zx265C799B18CE4D6DE5A3671D65F5B018D713919204868A0F.nii.gz downloaded\n",
            "51/920: Zx27ECA58C0AE0031815C0AE04CA9002F10E1FCB7F5686AE48.nii.gz downloaded\n",
            "52/920: Zx28A11914F19501C527FADC7432C8E020873181C0B365E863.nii.gz downloaded\n",
            "53/920: Zx2821AF61A3DBB7F40C01DEA2F7BBAE3C7FB59CA82BC55B55.nii.gz downloaded\n",
            "54/920: Zx291FD6850838B643BC1A7878279A2373C32A719B91C042EC.nii.gz downloaded\n",
            "55/920: Zx28CA9394EF10537307B5B8DDC24D756E20354ED9E8B3237A.nii.gz downloaded\n",
            "56/920: Zx28C2905F39B77B64E242963BF9BA3069E135FDCC8A782720.nii.gz downloaded\n",
            "57/920: Zx29249C3340706D8A658BC96F288DE057693CDCA0C50018FF.nii.gz downloaded\n",
            "58/920: Zx29D944DDC12D73E641FD78628DA3CCDAD0CCD13F9C098056.nii.gz downloaded\n",
            "59/920: Zx29D944DDC12D73E608734644C33D08170EC666B3E934AE93.nii.gz downloaded\n",
            "60/920: Zx2933A24F5182C585C1ADECFA9FF9EDDB3F9432CBB9E30A24.nii.gz downloaded\n",
            "61/920: Zx2AAE948072335FDABDFFA2D972B5638F4069A5D8D0B432B8.nii.gz downloaded\n",
            "62/920: Zx2A1210AAD0C7673D871C9B73A00CC394F65B0A224D6EABC9.nii.gz downloaded\n",
            "63/920: Zx2A3C9F90B97FC5CF48D8F0046D61E7AA7B868D85B83054AE.nii.gz downloaded\n",
            "64/920: Zx2B401975A0A7FE26B9906E1047BB2A92BC4D80CCC69F0DC8.nii.gz downloaded\n",
            "65/920: Zx2AB19BB5DD94C321AF90101CD847A97A335713B9A85CD6E3.nii.gz downloaded\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-4aaa5e06e47a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# print(f\"下载 {name} 进度: {int(status.progress() * 100)}%\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mnext_chunk\u001b[0;34m(self, num_retries)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         resp, content = _retry_request(\n\u001b[0m\u001b[1;32m    742\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Make the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         response, content = self.http.request(\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     (response, content) = self._request(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcachekey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                 \u001b[0;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0o3a7eXiV7b",
        "outputId": "7d4a55c5-a9c9-4141-847e-ba4d7d8ae5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.80.136.131"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kora.xattr import get_id\n",
        "import requests\n",
        "from fake_useragent import UserAgent\n",
        "import time\n",
        "\n",
        "# user_agents = [\n",
        "#     \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\",  # Chrome on Windows 10\n",
        "#     \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\",  # Safari on macOS\n",
        "#     \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:88.0) Gecko/20100101 Firefox/88.0\",  # Firefox on Windows 10\n",
        "#     \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\",  # Safari on iPhone\n",
        "#     \"Mozilla/5.0 (Linux; Android 10; SM-G973F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.210 Mobile Safari/537.36\",  # Chrome on Android\n",
        "#     \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:88.0) Gecko/20100101 Firefox/88.0\"  # Firefox on Ubuntu Linux\n",
        "# ]\n",
        "# headers = {\n",
        "#     'User-Agent': random.choice(user_agents)\n",
        "# }\n",
        "ua = UserAgent()\n",
        "\n",
        "files_on_drive = os.listdir(drive_rootdir+'/'+datadir)\n",
        "files_in_localdir = os.listdir(f\"/content/{datadir}\")\n",
        "files_to_download = [f for f in files_on_drive if f not in files_in_localdir]\n",
        "files = [(filename, get_id(f'{drive_rootdir}/{datadir}/{filename}')) for filename in files_to_download]\n",
        "# print(headers)\n",
        "\n",
        "t = random.randint(20,30)\n",
        "\n",
        "with requests.Session() as session:\n",
        "  for idx, (name, id) in enumerate(files):\n",
        "    headers = {'User-Agent': ua.random}\n",
        "    # print(headers)\n",
        "    url = f\"https://drive.google.com/uc?id={id}&confirm=t\"\n",
        "    # url = f\"https://drive.google.com/file/d/{id}/view?usp=drive_link\"\n",
        "    # url = f\"https://drive.google.com//uc?id={id}&confirm=t&usp=sharing\"\n",
        "    response = session.get(url, headers=headers, allow_redirects=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(f\"/content/{datadir}/{name}\", 'wb') as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"{idx+1}/{len(files)}: {name}\")\n",
        "    elif response.status_code == 403:\n",
        "        print(f\"Error: Unable to download file. Status code: {response.status_code}\")\n",
        "        # headers = {\n",
        "        #   'User-Agent': random.choice(user_agents)\n",
        "        # }\n",
        "        # print(headers)\n",
        "        s = random.randint(300,600)\n",
        "        print(f\"sleeping {s} secondes...\")\n",
        "        time.sleep(s)\n",
        "    else:\n",
        "        print(f\"Error: Unable to download file. Status code: {response.status_code}\")\n",
        "\n",
        "    # if (idx+1) % t  == 0:\n",
        "    #   s = random.randint(60,300)\n",
        "    #   print(f\"sleeping {s} secondes...\")\n",
        "    #   time.sleep(s)\n",
        "    #   t = random.randint(20,30)\n",
        "\n",
        "# files_on_drive = os.listdir(drive_rootdir+'/'+datadir)\n",
        "# files_in_localdir = os.listdir(f\"/content/{datadir}\")\n",
        "# files_to_download = [f for f in files_on_drive if f not in files_in_localdir]\n",
        "# files = [(filename, get_id(f'{drive_rootdir}/{datadir}/{filename}')) for filename in files_to_download]\n",
        "# for idx, (name, id) in enumerate(files):\n",
        "#   gdown.download(f\"https://drive.google.com/uc?id={id}&confirm=t\", output=f\"/content/{datadir}/{name}\", quiet=True, use_cookies=False)\n",
        "#   print(f\"{idx+1}/{len(files)}: {name}\")"
      ],
      "metadata": {
        "id": "RUZd5b8QlKRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(datadir))"
      ],
      "metadata": {
        "id": "xXH5tN8Jq4Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f7e44b-311b-4b7d-8f82-b1af9e91f8df"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 測試直接從mount下載\n",
        "# labelpath = '/content/drive/MyDrive/AOCR2024/TrainValid_ground_truth.csv'\n",
        "# datadir =\"/content/drive/MyDrive/AOCR2024/Train_Valid_Image\"\n",
        "\n",
        "# process_data2(termi=5,shift=0,dropFalse=0,dropPos=0)"
      ],
      "metadata": {
        "id": "vWZgPEJQ0C9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 測試下載\n",
        "# labelpath = '/content/drive/MyDrive/AOCR2024/TrainValid_ground_truth.csv'\n",
        "\n",
        "# dflabel = read_label(labelpath)\n",
        "# images, labels, _ =  process_data2(termi=3,shift=2,dropFalse=0,dropPos=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzXqivsbxDmZ",
        "outputId": "b9d47b5c-0e87-49dc-aa36-4738833d65d3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xlim=[60, 316]\n",
            "ylim=[150, 406]\n",
            "zlim=[11, 71]\n",
            "Process 0: Zx0AA2C956EEA5EAEA0DC0DA2606A8F8D0F334B97FDD860E1F finished...\n",
            "Process 1: Zx08DA48B45B5C7D0182C369B8E0B013CAF9EEA43199E8AFEF finished...\n",
            "Process 2: Zx0800DE5C96380322E442453B99E25D6F1282F2C4A610A497 finished...\n",
            "read 3 scans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# s1 = labels[0:60]\n",
        "# s2 = labels[60:120]\n",
        "# s3 = labels[120:180]\n",
        "# s2"
      ],
      "metadata": {
        "id": "m-pRFYuy0xca"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0ME8m8YBRFR"
      },
      "source": [
        "# 資料處理"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labelpath = '/content/drive/MyDrive/AOCR2024/TrainValid_ground_truth.csv'\n",
        "\n",
        "dflabel = read_label(labelpath)\n",
        "total_nii = len(os.listdir(datadir))\n",
        "images, labels, _ =  process_data2(termi=total_nii,shift=0,dropFalse=0,dropPos=0)"
      ],
      "metadata": {
        "id": "WFJpwdc4cSci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5c0b53-6c71-4f5d-ddd5-29f551d1b8dc"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xlim=[60, 316]\n",
            "ylim=[150, 406]\n",
            "zlim=[11, 71]\n",
            "Process 0: Zx0B06041DB37FAF0160B564B48791D3B58804B731DD57F4AB finished...\n",
            "Process 1: Zx0CA5CE197AA9378EE23F949BDFC91790D4FED5D6FD06F5A2 finished...\n",
            "Process 2: Zx0AA2C956EEA5EAEA0DC0DA2606A8F8D0F334B97FDD860E1F finished...\n",
            "Process 3: Zx08DA48B45B5C7D0182C369B8E0B013CAF9EEA43199E8AFEF finished...\n",
            "Process 4: Zx0800DE5C96380322E442453B99E25D6F1282F2C4A610A497 finished...\n",
            "Process 5: Zx0BCA7F5108A7E8BCC2AB6094DE20A5C243897FCB0C82E20A finished...\n",
            "Process 6: Zx052D253409F40A03B71D313382692559FB09F771A41F754A finished...\n",
            "Process 7: Zx16F4FD8907D539630058B97C3DA72D8CE2C4154A1011F3D7 finished...\n",
            "Process 8: Zx00AD16F8B97A53DE6E7CFE260BDF122F0E655659A3DF1628 finished...\n",
            "Process 9: Zx00FE1B9A88E88C71F8D11F50C2B5FBFEB3461E67BE1E83B8 finished...\n",
            "Process 10: Zx0F09553E6591D068AAB2811C40BA511B70E378F39A37839A finished...\n",
            "Process 11: Zx04424F2CF83E0AD3DDF3CC99A41482D909CBC495238F2FEC finished...\n",
            "Process 12: Zx0CE3BA2363A72325A7BB82B688463DBB79D224C67883F062 finished...\n",
            "Process 13: Zx07C5208D04A267A61BFB6EC968FBBB3DF25C245A6893273D finished...\n",
            "Process 14: Zx014E4DF04789E7E61C3B4876CE4D122DC14E0BB842E42E7D finished...\n",
            "Process 15: Zx05576CE976F91BF416232FAF4CDF5F6C5DF852ADCA2B9DD8 finished...\n",
            "Process 16: Zx188AD4803C40A1FBE691B933154BA5659529C18A8032265F finished...\n",
            "Process 17: Zx081F9B5A0C06A23AE10DC1E14E6B9B4DFC71FBCF3B559AEB finished...\n",
            "Process 18: Zx09972B8FA6215EEC75DB4194B16C000F47B5F87AFB64A12B finished...\n",
            "Process 19: Zx1843C96056436B4D91A7A4727E773B3964907516AA7E203F finished...\n",
            "Process 20: Zx19075B1C1417E664BEDD1C5C7F782D359A1DC198D01A79DF finished...\n",
            "Process 21: Zx12530E751E5315C38EEF85D4C1B0308338838B8C2983106D finished...\n",
            "Process 22: Zx0E392B7839BC0EDBDA8BEAC12F819B61409DC2804FB3F997 finished...\n",
            "Process 23: Zx0A1564C092259CD377329E07006281E876D09F9B48E77002 finished...\n",
            "Process 24: Zx0800DE5C96380322C65ABA398FC93B5CBDF75B20B11DDF6E finished...\n",
            "Process 25: Zx12CD0450CBDF59B92B8BFF3AE5296DF73C619990C8117DCE finished...\n",
            "Process 26: Zx0E64921E82ED12C88791307B1B09E979ADC3FBD3845D3927 finished...\n",
            "Process 27: Zx09D290397499695039422FD2002292BD781E5203436441A3 finished...\n",
            "Process 28: Zx162F641C827B6EE83C571BF7AEA8A018024AC788B8C0B158 finished...\n",
            "Process 29: Zx114AC1555B9AD6790B7A1BDE0521553F4A9A83AEAF30A859 finished...\n",
            "Process 30: Zx14087FD7C271A7D92C0F8CF2AD8131123F9C59DAE6DA5705 finished...\n",
            "Process 31: Zx12530E751E5315C3F09F11CFCE42D6BA786BE280C8BA5C5D finished...\n",
            "Process 32: Zx16D93043D5D4E4D3393FB6C9DC8E305AA39CC4FCDD1B952F finished...\n",
            "Process 33: Zx10E5A02B21E2368FB1C4CE0CBD7EFC890FAA56ECB35CBED2 finished...\n",
            "Process 34: Zx0D204781E3C58AD6EB37CC2E6EC18B935B00F9CC5D987220 finished...\n",
            "Process 35: Zx09413D933AD838CE8DB00704AB349855FE4721FC26037F37 finished...\n",
            "Process 36: Zx1843C96056436B4D01517C950238025999165FE4A16A8110 finished...\n",
            "Process 37: Zx016CBC4284052F6A74A56DAFFB0B39B95D4DEC066028AA4A finished...\n",
            "Process 38: Zx0C72F2127A469CAA6A49C516DC18B2706A43700721B5D8AB finished...\n",
            "Process 39: Zx0E3C20D9BB248666701B02B803ECE6BC4306B85A53E6DE38 finished...\n",
            "Process 40: Zx0E96DE51997AF17C5C54835EAD6B7512C66F91BFDB491B9F finished...\n",
            "Process 41: Zx12E8C030B31F39B52D2C9FA262B92370A9C7BAFDA12373AF finished...\n",
            "Process 42: Zx04424F2CF83E0AD3059C7706FBE311FDC83AAA8265D2325D finished...\n",
            "Process 43: Zx0BA755CD6D068378215FE1AE4751945053ED5D2F2C2A40E7 finished...\n",
            "Process 44: Zx14E419FB0929647CE43F1FACB88A1F623BAF9D0F6836372F finished...\n",
            "Process 45: Zx13CC64ABE904CB3E29A95612A74C34E8F5F6B4BA181694BD finished...\n",
            "Process 46: Zx15FB4DF1D36A7B4A19617A2C71E216AC807960B0EF51AC83 finished...\n",
            "Process 47: Zx1761966B642ABA595F2D8E53DAED57654117D2271DF05D4B finished...\n",
            "Process 48: Zx12E8C030B31F39B5C62831916119C7108A9A7C2EA7625746 finished...\n",
            "Process 49: Zx13380F22EFEA0B62205EC17938D2A84A71C8153C1D25B7CF finished...\n",
            "Process 50: Zx1060A72A4F5C5FFE63F395F263138C39C901CEA1B608B5D3 finished...\n",
            "Process 51: Zx0CAA076280D8EBEAA52926C4C6F1DB221F5C58F6EC8B2593 finished...\n",
            "Process 52: Zx15FB4DF1D36A7B4AA9B00B4D8DE5B757A9EDD1490640008D finished...\n",
            "Process 53: Zx01F90B532F87127D864B9194B92EDDC3B0EA988ABB5E1D1C finished...\n",
            "Process 54: Zx0A5FF3169135AF89B21F2A97A7278E517EC8B499B0F14C20 finished...\n",
            "Process 55: Zx117267214EB944C6E8593100AAC6E8FE5D47143C67350F53 finished...\n",
            "Process 56: Zx11E4702AA837EC465D5D80C1BC23104AD4388C527E94033D finished...\n",
            "Process 57: Zx0CFB1637BD27964BE741B2AA07BC7C84B2B61731E47782E0 finished...\n",
            "Process 58: Zx171AFF296B798AB09AD7911E3669EB7736CE2062AE9F80DA finished...\n",
            "Process 59: Zx0AE5424009C101F7422C5BD9DD2C3B0E13E834114A32883A finished...\n",
            "Process 60: Zx171AFF296B798AB089F4652DF7A4E18DF96CFEE1B08244E8 finished...\n",
            "Process 61: Zx0800DE5C96380322A41C31B46264D40D1B72FEC49745785C finished...\n",
            "Process 62: Zx12E8C030B31F39B5C0374AE9C7AA0FD527E0F819E430AA4D finished...\n",
            "Process 63: Zx15FB4DF1D36A7B4AD94C813D415FA88503C2381519A8357D finished...\n",
            "Process 64: Zx0CFEAEA49D4E19D1219A4C230C6D82751179B29EE9CA9F49 finished...\n",
            "Process 65: Zx09D29039749969505F54A1E8982B5BF5670F5EEABAE98ECF finished...\n",
            "Process 66: Zx17405CFB23569FC22C6738129E6305B6EF0398BE89533406 finished...\n",
            "Process 67: Zx14E419FB0929647C385FCFE5FC3DE04521DBD602302EC152 finished...\n",
            "Process 68: Zx018905C639589E81D4C91553041B845F583C3365B076C8E1 finished...\n",
            "Process 69: Zx0534778884B0E2267FCC4CF2BBF361589CD1D845F4A9C9DB finished...\n",
            "Process 70: Zx0E094D2402D05592511D0DED9E7ED9E999B468C249E9253F finished...\n",
            "Process 71: Zx01F90B532F87127DB647612B6621F2065CA58692B921CEB4 finished...\n",
            "Process 72: Zx015DF8E20804DB94E24A9B2D9DD387A47EF1C620A02026DC finished...\n",
            "Process 73: Zx00FE1B9A88E88C71CF81D0736F23E88BB9C35E2BCDECF501 finished...\n",
            "Process 74: Zx0494BD052F6F8D5A583699BBC329C318AC7B5BE50FD9ACDA finished...\n",
            "Process 75: Zx039B4A139FC862D542D2AACC247C46DFCE9EAA705B5DEF40 finished...\n",
            "Process 76: Zx12530E751E5315C37CEE489CA53DAD4806EAF276AEC9F18B finished...\n",
            "Process 77: Zx152DDBF3A8894FFDC2C923DF7F1099488C30A8943FE31860 finished...\n",
            "Process 78: Zx160CFC2664FE311B6AC70F6906A5E84B13D273AD7B24162B finished...\n",
            "Process 79: Zx06DF7CE50F0A454CB7E53B3918C49334BFB49CACC36B7438 finished...\n",
            "read 80 scans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %reset_selective images"
      ],
      "metadata": {
        "id": "jeAD7ynnVOWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %reset"
      ],
      "metadata": {
        "id": "ZWaEl6uf0eLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IX5HYZuSKG-"
      },
      "source": [
        "# 訓練 (EfficiencyNetV2_m)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "PjcZY1-Oehib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"tf_efficientnetv2_m\"\n",
        "pretrained_model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "# 修改輸入通道\n",
        "pretrained_model.conv_stem = nn.Conv2d(1, 24, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "# 修改輸出類別\n",
        "num_classes = 1\n",
        "pretrained_model.classifier = nn.Linear(pretrained_model.classifier.in_features, num_classes)\n",
        "\n",
        "# 添加 Sigmoid 激活函數\n",
        "pretrained_model = nn.Sequential(\n",
        "    pretrained_model,\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# 檢查模型結構\n",
        "# print(pretrained_model)\n"
      ],
      "metadata": {
        "id": "jZ0cSVS51BHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def between_epoch():\n",
        "  del images, labels\n",
        "  images, labels, _ = process_data2(termi=total_nii, shift=0,dropFalse=0.8, dropPos=0)\n",
        "  dataset = CustomDataset(images, labels)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "Ykire39uf_n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdKCQjs_Ozum"
      },
      "outputs": [],
      "source": [
        "# 訓練參數\n",
        "num_epochs = 10\n",
        "batch_size = 8\n",
        "lr = 0.01\n",
        "running_loss_list = []\n",
        "\n",
        "# 初始化模型、損失函數和優化器\n",
        "model = pretrained_model\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "model = model.to(device)\n",
        "\n",
        "dataset = CustomDataset(images, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_images, batch_labels in dataloader:\n",
        "        batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_images)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    dataloader = between_epoch()\n",
        "\n",
        "    running_loss_list.append(running_loss/len(dataloader))\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhLO9PaUESQh"
      },
      "source": [
        "## Loss圖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvRouRxFEXy2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1,num_epochs+1)[:len(running_loss_list)], running_loss_list)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRrn6mOmBRFU"
      },
      "source": [
        "# 儲存模型參數\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jnh7hW3BRFU"
      },
      "outputs": [],
      "source": [
        "filename = save_model(model)\n",
        "\n",
        "params = {\n",
        "    'num_epochs': num_epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': lr,\n",
        "}\n",
        "\n",
        "if os.path.isfile(filename+'.json'):\n",
        "    print(f\"{filename}.json exist.\")\n",
        "else:\n",
        "    with open(f'{filename}.json', 'w') as f:\n",
        "        json.dump(params, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBcppdev6LlG"
      },
      "source": [
        "# 讀取模型參數"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = pretrained_model\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "id": "Pfx0VwbRN9uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NUlm7dg5sRE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "filename = input(\"請輸入要獲取模型路徑:\")\n",
        "\n",
        "if not os.path.isfile(filename+'.pth'):\n",
        "    print(f\"{filename}.pth not exist.\")\n",
        "else:\n",
        "    print(model.load_state_dict(torch.load(filename+'.pth')))\n",
        "\n",
        "with open(f'{filename}.json', 'r') as f:\n",
        "    params = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v_lVRL47kzj"
      },
      "source": [
        "# 評估\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data(\"TrainValid_Image/train_data\",termi=80,shift=80)\n",
        "# data = read_data(\"Test1_Image/test_data\",termi=3,shift=1)\n",
        "dflabel = read_label(\"TrainValid_ground_truth.csv\")"
      ],
      "metadata": {
        "id": "uLNoNdr155p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels,info = process_data(data, dflabel)"
      ],
      "metadata": {
        "id": "4ZfJbfii6FFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtWJ-YYy5l2E"
      },
      "outputs": [],
      "source": [
        "# 評估設置\n",
        "num_epochs = params['num_epochs']\n",
        "batch_size = params['batch_size']\n",
        "\n",
        "#最後data不滿一個batch\n",
        "num_batches = len(images) // batch_size\n",
        "if len(images) % batch_size != 0:\n",
        "  num_batches += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M1qST-FslSs"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "predict_list = torch.tensor([]).to(device)\n",
        "with torch.no_grad():  # 不更新梯度\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in range(num_batches):\n",
        "        batch_images = images[i*batch_size:(i+1)*batch_size].to(device)\n",
        "        batch_labels = labels[i*batch_size:(i+1)*batch_size].to(device)\n",
        "\n",
        "        outputs = model(batch_images)\n",
        "        predicted = (outputs.squeeze() > 0.5).int()\n",
        "        if predicted.dim() == 0:\n",
        "          predicted = predicted.unsqueeze(0)\n",
        "        predict_list = torch.cat((predict_list,predicted),0)\n",
        "\n",
        "\n",
        "predict_listq = predict_list.cpu()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s7klq4YR5Qg"
      },
      "outputs": [],
      "source": [
        "print_results(predict_listq, labels[:len(predict_list)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml59tSf2QXty"
      },
      "source": [
        "# 輸出至submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cont(l):\n",
        "  \"1是否連續\"\n",
        "  f1 = False\n",
        "  f2 = False\n",
        "  for i in range(len(l)):\n",
        "    if (l[i] == 1):\n",
        "      f1 = True\n",
        "    if (l[i] == 0):\n",
        "      if (f1):\n",
        "        f2 = True\n",
        "    if (l[i] == 1) and f2:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def yes(predict):\n",
        "  return int(sum(predict) >= 3)\n",
        "\n",
        "\n",
        "\n",
        "predict_list = predict_listq.numpy()\n",
        "\n",
        "## 還原id與對應label，假設key按照scan輸入順序排列,每個key對應的scan的cuts數是nslice\n",
        "output = {}\n",
        "k = 0  #第幾個scan\n",
        "ii = 0   #每個key輪到第幾個\n",
        "id, nslice = info[k][0], info[k][1]\n",
        "for i in range(len(predict_list)):\n",
        "\n",
        "  if (ii >= nslice):\n",
        "    #該換下一個scan了\n",
        "    output[id] = yes(predict_list[i-nslice:i]) #評估方式\n",
        "\n",
        "    k += 1\n",
        "    ii = 0\n",
        "    id, nslice = info[k][0], info[k][1]\n",
        "\n",
        "  label = predict_list[i]\n",
        "  output[id+f'_{ii}'] = int(predict_list[i])\n",
        "  ii += 1\n",
        "\n",
        "output[id] = yes(predict_list[(i+1)-ii:]) #補上最後一個scan評估\n",
        "# import pdb\n",
        "# pdb.set_trace()\n",
        "output = list(output.items())\n",
        "dfout = pd.DataFrame(output)\n",
        "dfout.columns = ['id', 'label']\n",
        "dfout = dfout.sort_values(by='id', key=lambda x: x.map(custom_sort_key))\n",
        "filename = input(\"輸入提交檔名(enter for submission)\")\n",
        "if filename == '':\n",
        "  filename = 'submission'\n",
        "dfout.to_csv(filename+'.csv', index=False)"
      ],
      "metadata": {
        "id": "eGcPvyce5uDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "id": "T2eaN23dXgfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhDYVsGNxVTZ"
      },
      "outputs": [],
      "source": [
        "dfout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 查看submission.csv"
      ],
      "metadata": {
        "id": "wKe-NfBAeN8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "lC6LJpkZr4xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dftest = read_submission('fisrt_80.csv')\n",
        "# dftest = read_submission('submission.csv')\n",
        "dflabel = read_label(\"TrainValid_ground_truth.csv\")"
      ],
      "metadata": {
        "id": "oDM_yM-5bdCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dftest)"
      ],
      "metadata": {
        "id": "fRSaPgTBnbE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# 抓出scan-level data\n",
        "pattern = re.compile(r'.*_[0-9]+$')  # 正則表達式匹配 \"_數字\" 結尾\n",
        "mask = ~dftest.index.str.match(pattern)\n",
        "scan_guess = np.array(dftest[mask]['label'])\n",
        "scan_truth = np.array(dflabel.loc[dftest[mask]['label'].index]['label'])\n",
        "\n",
        "mask = ~mask\n",
        "cut_guess = np.array(dftest[mask]['label'])\n",
        "cut_truth = np.array(dflabel.loc[dftest[mask]['label'].index]['label'])"
      ],
      "metadata": {
        "id": "BD1NfxWTb2iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 10\n",
        "print(\"=\"*ss + \"F1 score on scan level\" + \"=\"*ss)\n",
        "print_results(scan_guess, scan_truth)\n",
        "print(),print()\n",
        "print(\"=\"*ss + \"F1 score on cut level\" +\"=\"*ss )\n",
        "print_results(cut_guess, cut_truth)"
      ],
      "metadata": {
        "id": "fyMlAtUWuW8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 其他指令\n",
        "不在工作流\n",
        "當參考"
      ],
      "metadata": {
        "id": "FG2tqJ1kMhzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "datadir = 'Train_Valid_Image'\n",
        "for idx, afile in enumerate(os.listdir(datadir)):\n",
        "  file_path = os.path.join(datadir, afile)\n",
        "  time.sleep(1)\n",
        "  nii_file =  nib.load(file_path)\n",
        "  print(f\"{idx}: read {afile}\")"
      ],
      "metadata": {
        "id": "eazF7afOHa8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'.*_[0-9]+$')  # 正則表達式匹配 \"_數字\" 結尾\n",
        "mask = dftest.index.to_series().str.match(pattern)\n",
        "dflabel_ = dftest[mask]\n",
        "dflabel_.index.map(lambda x : x.split('_')[1]).sort_values()[-3:]"
      ],
      "metadata": {
        "id": "lEForON9S9qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 假設這是您的列表\n",
        "my_list = np.array([1, 2, 3, 4])\n",
        "\n",
        "mask = [True, False, False, True]\n",
        "my_list[mask]"
      ],
      "metadata": {
        "id": "37C0pWRQTCyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datadir =\"TrainValid_Image/train_data\"\n",
        "labelpath = 'TrainValid_ground_truth.csv'\n",
        "labels_ = read_label(labelpath)\n",
        "\n",
        "\n",
        "filelist = os.listdir(datadir)\n",
        "filelist = filelist[10:20]\n",
        "selecteds = [labels_.loc[labels_.index.str.startswith(afile.strip('.nii')+'_')] for afile in filelist]\n",
        "scans_info = []\n",
        "# preallocated\n",
        "print(\"enter\")\n",
        "numcuts = [len(selected) for selected in selecteds]\n",
        "numcut = sum(numcuts)"
      ],
      "metadata": {
        "id": "el4YgUCT6LgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numcuts = [len(selected) for selected in selecteds]"
      ],
      "metadata": {
        "id": "TBvrMIwo6nhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = nib.load('Train_Valid_Image/Zx00AD16F8B97A53DE6E7CFE260BDF122F0E655659A3DF1628.nii.gz')\n"
      ],
      "metadata": {
        "id": "E9rP7qJsIFZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "RFBfoC3iMo1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.randint(3,(5,1,2,2))\n",
        "lab = torch.tensor([1,1,1,1,1])\n",
        "t1"
      ],
      "metadata": {
        "id": "v3E6Q2z4R6-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_positive_images(t1,lab,0.79)"
      ],
      "metadata": {
        "id": "vMKO8czxSMd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown gdown"
      ],
      "metadata": {
        "id": "-WWE6jOKCD0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "v57WjC4VAtaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/1C7HXpHMw1Alvwif9hO97FUzfn4rhxG8B -O Train_Valid_Image --folder --remaining-ok"
      ],
      "metadata": {
        "id": "1T5_yrOg7RLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RpwX2ZFOBRFT",
        "0IX5HYZuSKG-",
        "rhLO9PaUESQh"
      ],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}