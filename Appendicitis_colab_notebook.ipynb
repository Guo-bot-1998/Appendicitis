{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guo-bot-1998/Appendicitis/blob/master/Appendicitis_colab_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coYrDLBnCbwQ"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4kBLfXWRg7N"
      },
      "outputs": [],
      "source": [
        "!pip install timm\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ4w8h2LkY0g"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import re\n",
        "import tqdm\n",
        "import timm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 常用功能"
      ],
      "metadata": {
        "id": "BdwzEjFhbR4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7dmJYugUB_3w"
      },
      "outputs": [],
      "source": [
        "\n",
        "def count_zero(images):\n",
        "  count = 0\n",
        "  for image in images:\n",
        "    if not torch.any(image):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "def cropping(image):\n",
        "  if image.shape[2] != 512:\n",
        "    start = (image.shape[2] - 512) // 2\n",
        "    end = start + 512\n",
        "    image = image[:, :, start:end, :]\n",
        "\n",
        "  if image.shape[3] != 512:\n",
        "    start = (image.shape[3] - 512) // 2\n",
        "    end = start + 512\n",
        "    image = image[:, :, :, start:end]\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "def read_label(excel_path) -> pd.DataFrame:\n",
        "  \"\"\"Reads a csv file containing ground-truth.\n",
        "    The csv file should have two columns: 'id' and 'label'.\n",
        "  \"\"\"\n",
        "  with open(excel_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "    df.set_index('id', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def write_error(logpath, e, nprocess):\n",
        "  # with open(logpath, 'a') as f:\n",
        "    # f.write(f\"{nprocess:} error occured: {e}\\n\") ##! may stuck the program!!\n",
        "  print(f\"{nprocess:} error occured: {e}\\n\")\n",
        "\n",
        "\n",
        "def read_submission(excel_path) -> pd.DataFrame:\n",
        "  \"\"\"Reads a csv file containing submission file.\n",
        "    The csv file should follow the format given by Kaggle.\n",
        "  \"\"\"\n",
        "  with open(excel_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "    df.set_index('id', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def process_data2(shift=0, termi=10, drop=0.85)\\\n",
        " -> tuple[torch.tensor, torch.tensor, list[tuple[str, int]]]:\n",
        "  \"\"\"Process the data, get the id and number of each scan, and merge the images and labels.\n",
        "\n",
        "  Args:\n",
        "      data: The data of the scans\n",
        "      labels: The labels of the scans\n",
        "\n",
        "  Returns:\n",
        "      A tuple of images, labels, and (id, # of cuts) of each scan\n",
        "  \"\"\"\n",
        "\n",
        "  \"Memory efficiency version of process_data\"\n",
        "\n",
        "  labels_ = read_label(labelpath)\n",
        "\n",
        "  if labels_.index.name != 'id':\n",
        "    labels_.set_index('id', inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "  filelist = os.listdir(datadir)\n",
        "  filelist = filelist[shift:shift+termi]\n",
        "  selecteds = [labels_.loc[labels_.index.str.startswith(afile.strip('.nii.gz')+'_')] for afile in filelist]\n",
        "  scans_info = []\n",
        "  # preallocated\n",
        "  numcuts = [len(selected) for selected in selecteds]\n",
        "  images = torch.zeros((sum(numcuts),1, 512,512))\n",
        "  labels = -torch.ones((sum(numcuts)))\n",
        "  nimgs = 0\n",
        "  nprocess = 0\n",
        "\n",
        "  debug = 0\n",
        "\n",
        "  for key in filelist:\n",
        "    file_path = os.path.join(datadir, key)\n",
        "    key = key.strip('.nii.gz')\n",
        "    scan  = labels_.loc[labels_.index.str.startswith(key+'_')]\n",
        "\n",
        "    value = nib.load(file_path).get_fdata()\n",
        "    scans_info.append((key, value.shape[2]))\n",
        "    label_t = torch.tensor(scan['label'])\n",
        "    image_t = torch.from_numpy(value).float().permute(2, 0, 1).unsqueeze(1)\n",
        "\n",
        "\n",
        "    if (image_t.shape[2] != 512 or image_t.shape[3] != 512):\n",
        "      image_t = cropping(image_t)\n",
        "    image_t, label_t = remove_false_images(image_t, label_t, drop)\n",
        "    n_new = len(label_t)\n",
        "    images[nimgs:nimgs+n_new] = image_t\n",
        "    labels[nimgs:nimgs+n_new] = label_t\n",
        "    nimgs += len(label_t)\n",
        "    print(f\"Process {nprocess}: {key} finished...\")\n",
        "    nprocess += 1\n",
        "\n",
        "  print(f\"read {len(scans_info)} scans\")\n",
        "\n",
        "  return images, labels.float(), scans_info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def argumenting(images, labels, n=5):\n",
        "  where = (labels == True).nonzero(as_tuple=True)[0]\n",
        "  bad_images = images[where]\n",
        "\n",
        "  rep_imgs = bad_images.repeat(n, 1, 1, 1)\n",
        "  rep_labels = torch.ones(rep_imgs.shape[0], dtype=labels.dtype)\n",
        "\n",
        "  # import pdb\n",
        "  # pdb.set_trace()\n",
        "  # 隨機插入argumented圖片\n",
        "  nimg = images.shape[0]\n",
        "  rnd_pos = torch.randint(0, nimg, (rep_imgs.shape[0],))\n",
        "  images = torch.cat((images, rep_imgs), dim=0)\n",
        "  images = images[torch.argsort(torch.cat((torch.arange(nimg), rnd_pos)))]\n",
        "\n",
        "  # 對應對置插入標籤\n",
        "  labels = torch.cat((labels, rep_labels), dim=0)\n",
        "  labels = labels[torch.argsort(torch.cat((torch.arange(nimg), rnd_pos)))]\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "def remove_false_images(images, labels, ratio):\n",
        "    # 找出 labels == 0 的索引\n",
        "    where_false = (labels == 0).nonzero(as_tuple=True)[0]\n",
        "    mask = torch.ones(len(images), dtype=torch.bool)\n",
        "    indices_filter = torch.randperm(len(where_false))[:int(len(where_false)*ratio)]\n",
        "    mask[where_false[indices_filter]] = False\n",
        "    images = images[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "\n",
        "def get_confusion(guess, truth):\n",
        "  right = guess == truth\n",
        "  wrong = np.logical_not(right)\n",
        "  TP = np.sum(np.logical_and(right, truth == np.ones(right.shape)))\n",
        "  TN = np.sum(np.logical_and(right, truth == np.zeros(right.shape)))\n",
        "  FN = np.sum(np.logical_and(wrong, truth == np.ones(wrong.shape)))\n",
        "  FP = np.sum(np.logical_and(wrong, truth == np.zeros(wrong.shape)))\n",
        "  return (TP,FP,FN,TN)\n",
        "\n",
        "\n",
        "\n",
        "def print_results(prediction, labels):\n",
        "  if torch.is_tensor(prediction):\n",
        "    prediction = prediction.cpu().numpy()\n",
        "  if torch.is_tensor(labels):\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "  TP,FP,FN,TN = get_confusion(prediction, labels)\n",
        "  print(f\"\\n\\\n",
        "      真實值\\n\\\n",
        "  預  +-----+-----+\\n\\\n",
        "  測| TP: {TP}| FP: {FP}|\\n\\\n",
        "  值| FN: {FN}| TN: {TN}|\\n\\\n",
        "      +-----+-----+ \\n\")\n",
        "\n",
        "  recall = TP/(TP + FN)\n",
        "  precision = TP/(TP + FP)\n",
        "  recall = 0 if np.isnan(recall) else recall.item()\n",
        "  precision = 0 if np.isnan(precision) else precision.item()\n",
        "  F1 = 0 if recall + precision == 0 else  (2*recall*precision/(recall+precision))\n",
        "\n",
        "  print(f\"{recall=}\\n{precision=}\\n{F1=}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def custom_sort_key(val):\n",
        "    parts = val.split('_')\n",
        "    if len(parts) == 2 and parts[1].isdigit():\n",
        "        return (parts[0], int(parts[1]))\n",
        "    return (parts[0], -1)  # 使沒有_(數字)的id排最前面\n",
        "\n",
        "\n",
        "def isgpu():\n",
        "    \"\"\"檢查是否有 CUDA 支持的 GPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"GPU is available\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        # raise(\"GPU not available\")\n",
        "    return device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "暫時沒用到"
      ],
      "metadata": {
        "id": "jqfoJ9tO8ahG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetchdata(readed:list, N:int, mode:str) -> tuple[torch.tensor, list[str]]:\n",
        "  \"\"\"隨機load進N個.nii檔案\"\"\"\n",
        "  labels_ = read_label(labelpath)\n",
        "  filelist = list(set(os.listdir(datadir)) - set(readed))\n",
        "  filelist = random.sample(datadir,N)\n",
        "  readed.append(filelist)\n",
        "\n",
        "  # preallocated\n",
        "  pattern = re.compile(r'.*_[0-9]+$')\n",
        "  mask = labels_.index.str.match(pattern)\n",
        "  cutids  = labels_[mask].index\n",
        "  cutnums = cutids.map(lambda x : int(x.split('_')[1])+1).sort_values()[-len(filelist):]\n",
        "  images = torch.zeros((len(filelist)*sum(cutnums),1, 512,512))\n",
        "  labels = -torch.ones((len(filelist)*sum(cutnums))) if mode=='train' else None\n",
        "  nimgs = 0\n",
        "\n",
        "  for idx, filename in tqdm(enumerate(filelist), total=len(filelist)):\n",
        "    nii_path = os.path.join(datadir, filename)\n",
        "    key = filename.strip('.nii')\n",
        "    value = nib.load(nii_path).get_fdata()\n",
        "\n",
        "    n_new = len(label_t)\n",
        "    if labels:\n",
        "      scan  = labels_.loc[labels_.index.str.startswith(key+'_')]\n",
        "      label_t = torch.from_numpy(scan['label'])\n",
        "      labels[nimgs:nimgs+n_new] = label_t\n",
        "    image_t = torch.from_numpy(value).float().permute(2, 0, 1).unsqueeze(1)\n",
        "\n",
        "    if (image_t.shape[2] != 512 or image_t.shape[3] != 512):\n",
        "      image_t = cropping(image_t)\n",
        "\n",
        "    images[nimgs:nimgs+n_new] = image_t\n",
        "    nimgs += len(label_t)\n",
        "\n",
        "\n",
        "  return images, labels.float() if labels else None"
      ],
      "metadata": {
        "id": "mf_ahm_m8VDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(directory, shift=0, termi=10) -> dict[str, np.array]:\n",
        "    \"\"\"Reads all the .nii files in a given directory and returns a dictionary.\n",
        "\n",
        "    The dictionary keys are the file names without the .nii extension. The dictionary\n",
        "    values are the corresponding numpy arrays.\n",
        "\n",
        "    Args:\n",
        "      directory: The directory containing the .nii files.\n",
        "      shift: The number of files to skip at the beginning of the directory.\n",
        "      termi: The number of files to be read in the directory.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of numpy arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    data_dict = {}\n",
        "    k = 0\n",
        "    ncut = 0\n",
        "    filelist = os.listdir(directory)\n",
        "    for afile in filelist:\n",
        "      if afile.endswith('.nii'):\n",
        "        if (k<shift):\n",
        "          k += 1\n",
        "          continue\n",
        "        file_path = os.path.join(directory, afile)\n",
        "        nii_file =  nib.load(file_path)\n",
        "        data = nii_file.get_fdata()\n",
        "        data_dict[afile.strip('.nii')] = data\n",
        "        ncut +=  1\n",
        "        if ncut == termi:\n",
        "          return data_dict\n",
        "    return data_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "Duke_dweFwQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud4x-GeICQxw"
      },
      "outputs": [],
      "source": [
        "device = isgpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV66iCZmCrBJ"
      },
      "source": [
        "# 掛載\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKUXzQOdBRFQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s8UZdV7BRFR"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/AOCR2024"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "5qbhdYNrGRxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 資料下載"
      ],
      "metadata": {
        "id": "3OZg-WX2NgQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/1C7HXpHMw1Alvwif9hO97FUzfn4rhxG8B -O Train_Valid_Image --folder --remaining-ok"
      ],
      "metadata": {
        "id": "1T5_yrOg7RLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0ME8m8YBRFR"
      },
      "source": [
        "# 資料處理"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('TrainValid_Image/train_data'))"
      ],
      "metadata": {
        "id": "WFJpwdc4cSci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datadir =\"Train_Valid_Image\"\n",
        "labelpath = '/content/drive/MyDrive/AOCR2024/TrainValid_ground_truth.csv'\n",
        "\n",
        "dflabel = read_label(labelpath)\n",
        "images2, labels2, info2 =  process_data2(termi=50,shift=0,drop=0)\n",
        "counts = count_zero(images2)\n",
        "images2 = torch.asarray(images2[:len(images2)-counts])\n",
        "labels2 = labels2[labels2 != -1]"
      ],
      "metadata": {
        "id": "FgZba6JN4rro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f8c0a0-b1b2-4595-cf38-183985bdf53c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0: Zx0CFB1637BD27964BE741B2AA07BC7C84B2B61731E47782E0 finished...\n",
            "Process 1: Zx1BBA21D9DA37F2D063D4A85F624E8D72C0410728E334B442 finished...\n",
            "Process 2: Zx0E96DE51997AF17C5C54835EAD6B7512C66F91BFDB491B9F finished...\n",
            "Process 3: Zx01F90B532F87127D864B9194B92EDDC3B0EA988ABB5E1D1C finished...\n",
            "Process 4: Zx0CAA076280D8EBEAA52926C4C6F1DB221F5C58F6EC8B2593 finished...\n",
            "Process 5: Zx1ECC8B15EE2388642B2C05331250EEB951BE580304D38622 finished...\n",
            "Process 6: Zx1F0951EDF2B31E5E932707FD021961BFCF8586E917ABD120 finished...\n",
            "Process 7: Zx00FE1B9A88E88C71F8D11F50C2B5FBFEB3461E67BE1E83B8 finished...\n",
            "Process 8: Zx1F0C08B15A2FA4B85694E240248D208FBA9CDCFA1B19D3E5 finished...\n",
            "Process 9: Zx1E550FA95B8A7552A06CE65E3BEED1EE034D46B71AC2990F finished...\n",
            "Process 10: Zx0E3C20D9BB248666701B02B803ECE6BC4306B85A53E6DE38 finished...\n",
            "Process 11: Zx0F09553E6591D068AAB2811C40BA511B70E378F39A37839A finished...\n",
            "Process 12: Zx0D204781E3C58AD6EB37CC2E6EC18B935B00F9CC5D987220 finished...\n",
            "Process 13: Zx1D4DA6EB30F0E21BAE9B15E262721240DDC420DD988AAC16 finished...\n",
            "Process 14: Zx0C72F2127A469CAA6A49C516DC18B2706A43700721B5D8AB finished...\n",
            "Process 15: Zx1A8AFCB885E0D8BC44A0ED9AEF59DD90D90777A8345747EE finished...\n",
            "Process 16: Zx2B7652752183E77F7E8BC4D7F8608C151B41BFCA53475095 finished...\n",
            "Process 17: Zx0B06041DB37FAF0160B564B48791D3B58804B731DD57F4AB finished...\n",
            "Process 18: Zx1BDF4C967678080E6779C2713B10F3B23CE3C1CC7F2CC8BB finished...\n",
            "Process 19: Zx0BCA7F5108A7E8BCC2AB6094DE20A5C243897FCB0C82E20A finished...\n",
            "Process 20: Zx0CE3BA2363A72325A7BB82B688463DBB79D224C67883F062 finished...\n",
            "Process 21: Zx01F90B532F87127DB647612B6621F2065CA58692B921CEB4 finished...\n",
            "Process 22: Zx00FE1B9A88E88C71CF81D0736F23E88BB9C35E2BCDECF501 finished...\n",
            "Process 23: Zx0AE5424009C101F7422C5BD9DD2C3B0E13E834114A32883A finished...\n",
            "Process 24: Zx0CA5CE197AA9378EE23F949BDFC91790D4FED5D6FD06F5A2 finished...\n",
            "Process 25: Zx00AD16F8B97A53DE6E7CFE260BDF122F0E655659A3DF1628 finished...\n",
            "Process 26: Zx0A5FF3169135AF89B21F2A97A7278E517EC8B499B0F14C20 finished...\n",
            "Process 27: Zx1F2D6E616335D5D7A26B93C9CBB01658781603DFF3B46DF8 finished...\n",
            "Process 28: Zx2AAE948072335FDABDFFA2D972B5638F4069A5D8D0B432B8 finished...\n",
            "Process 29: Zx1A5E6FEE5BA94F6D9C91E1BBACAE6959AB96EB6442A0524B finished...\n",
            "Process 30: Zx2A3C9F90B97FC5CF48D8F0046D61E7AA7B868D85B83054AE finished...\n",
            "Process 31: Zx1ED66EE4F0492C4C63EED347F5480C328DED4C1955880614 finished...\n",
            "Process 32: Zx0E094D2402D05592511D0DED9E7ED9E999B468C249E9253F finished...\n",
            "Process 33: Zx2B401975A0A7FE26B9906E1047BB2A92BC4D80CCC69F0DC8 finished...\n",
            "Process 34: Zx1A447D96D387B7C45053917769DF2A154E9A765A87D51A24 finished...\n",
            "Process 35: Zx0BA755CD6D068378215FE1AE4751945053ED5D2F2C2A40E7 finished...\n",
            "Process 36: Zx1A3FF9BBC87A0A6379CA804FA7025BE5E55D98B90E6E911E finished...\n",
            "Process 37: Zx0E64921E82ED12C88791307B1B09E979ADC3FBD3845D3927 finished...\n",
            "Process 38: Zx2AF7910D2CCF58C07FF4E3EFC228F15E7DBD8E71193CA7BF finished...\n",
            "Process 39: Zx0AA2C956EEA5EAEA0DC0DA2606A8F8D0F334B97FDD860E1F finished...\n",
            "Process 40: Zx2BCE9A7537D7DB08D8254B88EDFA79D2B5FAD113ED12B54E finished...\n",
            "Process 41: Zx1AC280D33D45A2973879438429EB6E09CB3DF1914B26DED8 finished...\n",
            "Process 42: Zx2A1210AAD0C7673D871C9B73A00CC394F65B0A224D6EABC9 finished...\n",
            "Process 43: Zx1C6B814369828D2A1FE29B8B7CD4D21752A8CB1AE56781F5 finished...\n",
            "Process 44: Zx2AB19BB5DD94C321AF90101CD847A97A335713B9A85CD6E3 finished...\n",
            "Process 45: Zx0A1564C092259CD377329E07006281E876D09F9B48E77002 finished...\n",
            "Process 46: Zx0E392B7839BC0EDBDA8BEAC12F819B61409DC2804FB3F997 finished...\n",
            "Process 47: Zx2BDF57DC47BEBC12CC3C156DC1BCE0C07D16D40692007D96 finished...\n",
            "Process 48: Zx1F83D85BC2A7A55A165937332E32D7646399FC21D7283669 finished...\n",
            "Process 49: Zx0CFEAEA49D4E19D1219A4C230C6D82751179B29EE9CA9F49 finished...\n",
            "read 50 scans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datadir =\"TrainValid_Image/train_data\"\n",
        "labelpath = 'TrainValid_ground_truth.csv'\n",
        "process_data2(termi=12,shift=3,drop=0)"
      ],
      "metadata": {
        "id": "yupHdNW2laVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %reset_selective images"
      ],
      "metadata": {
        "id": "jeAD7ynnVOWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %reset"
      ],
      "metadata": {
        "id": "ZWaEl6uf0eLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpwX2ZFOBRFT"
      },
      "source": [
        "# 訓練 (Unet with only encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbxXQeUUDWpp"
      },
      "outputs": [],
      "source": [
        "class FC(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(FC, self).__init__()\n",
        "\n",
        "        # Encoder部分\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.BatchNorm2d(1),  # Add BatchNorm after the first Conv2d\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),  # Add BatchNorm after the first Conv2d\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),  # Add BatchNorm after the second Conv2d\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),  # Add BatchNorm after the third Conv2d\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),  # Add BatchNorm after the fourth Conv2d\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(128 * 128 * 256, 1)  # x 和 y 是經過 encoder 處理後的特徵圖尺寸\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"tf_efficientnetv2_m\"\n",
        "pretrained_model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "# 修改輸入通道\n",
        "pretrained_model.conv_stem = nn.Conv2d(1, 24, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "# 修改輸出類別\n",
        "num_classes = 1\n",
        "pretrained_model.classifier = nn.Linear(pretrained_model.classifier.in_features, num_classes)\n",
        "\n",
        "# 添加 Sigmoid 激活函數\n",
        "pretrained_model = nn.Sequential(\n",
        "    pretrained_model,\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# 檢查模型結構\n",
        "# print(pretrained_model)\n"
      ],
      "metadata": {
        "id": "jZ0cSVS51BHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IX5HYZuSKG-"
      },
      "source": [
        "# 訓練 (EfficiencyNetV2_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdKCQjs_Ozum"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "num_epochs = 10\n",
        "batch_size = 6\n",
        "lr = 0.01\n",
        "num_batches = len(images) // batch_size  #最後data不滿一個batch丟棄\n",
        "# 初始化模型、損失函數和優化器\n",
        "# model = FC(in_channels=1).to(device)\n",
        "model = pretrained_model\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "model = model.to(device)\n",
        "\n",
        "running_loss_list = []\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "# Assuming you have 'images' and 'labels' as your original data\n",
        "dataset = CustomDataset(images, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_images, batch_labels in dataloader:\n",
        "        batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_images)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    running_loss_list.append(running_loss/len(dataloader))\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LuuNhizBRFT"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "batch_size = 16\n",
        "lr = 0.001\n",
        "num_batches = len(images) // batch_size  #最後data不滿一個batch丟棄\n",
        "# 初始化模型、損失函數和優化器\n",
        "model = FC(in_channels=1).to(device)\n",
        "# model = pretrained_model\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "\n",
        "running_loss_list = []\n",
        "\n",
        "# 訓練循環\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        batch_images = images[i*batch_size:(i+1)*batch_size].to(device)\n",
        "        batch_labels = labels[i*batch_size:(i+1)*batch_size].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_images)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    running_loss_list.append(running_loss/num_batches)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/num_batches}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhLO9PaUESQh"
      },
      "source": [
        "# Loss圖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvRouRxFEXy2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1,num_epochs+1)[:len(running_loss_list)], running_loss_list)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRrn6mOmBRFU"
      },
      "source": [
        "# 儲存模型參數\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX5worG8toux"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/AOCR2024/TrainValid_Image/train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jnh7hW3BRFU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "appendix = input(\"請輸入模型儲存的檔名:\")\n",
        "dirname = input(\"請輸入模型儲存的資料夾:\")\n",
        "filename = f\"params/{dirname}/{appendix}\"\n",
        "if not os.path.exists(dirname):\n",
        "  os.mkdir(dirname)\n",
        "\n",
        "if os.path.isfile(filename+'.pth'):\n",
        "    print(f\"{filename}.pth exist.\")\n",
        "else:\n",
        "    torch.save(model.state_dict(), f'{filename}.pth')\n",
        "\n",
        "params = {\n",
        "    'num_epochs': num_epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': lr,\n",
        "}\n",
        "\n",
        "if os.path.isfile(filename+'.json'):\n",
        "    print(f\"{filename}.json exist.\")\n",
        "else:\n",
        "    with open(f'{filename}.json', 'w') as f:\n",
        "        json.dump(params, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBcppdev6LlG"
      },
      "source": [
        "# 讀取模型參數"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = pretrained_model\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "id": "Pfx0VwbRN9uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NUlm7dg5sRE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "filename = input(\"請輸入要獲取模型路徑:\")\n",
        "\n",
        "if not os.path.isfile(filename+'.pth'):\n",
        "    print(f\"{filename}.pth not exist.\")\n",
        "else:\n",
        "    print(model.load_state_dict(torch.load(filename+'.pth')))\n",
        "\n",
        "with open(f'{filename}.json', 'r') as f:\n",
        "    params = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v_lVRL47kzj"
      },
      "source": [
        "# 評估\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data(\"TrainValid_Image/train_data\",termi=80,shift=80)\n",
        "# data = read_data(\"Test1_Image/test_data\",termi=3,shift=1)\n",
        "dflabel = read_label(\"TrainValid_ground_truth.csv\")"
      ],
      "metadata": {
        "id": "uLNoNdr155p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels,info = process_data(data, dflabel)"
      ],
      "metadata": {
        "id": "4ZfJbfii6FFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtWJ-YYy5l2E"
      },
      "outputs": [],
      "source": [
        "# 評估設置\n",
        "num_epochs = params['num_epochs']\n",
        "batch_size = params['batch_size']\n",
        "\n",
        "#最後data不滿一個batch\n",
        "num_batches = len(images) // batch_size\n",
        "if len(images) % batch_size != 0:\n",
        "  num_batches += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M1qST-FslSs"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "predict_list = torch.tensor([]).to(device)\n",
        "with torch.no_grad():  # 不更新梯度\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in range(num_batches):\n",
        "        batch_images = images[i*batch_size:(i+1)*batch_size].to(device)\n",
        "        batch_labels = labels[i*batch_size:(i+1)*batch_size].to(device)\n",
        "\n",
        "        outputs = model(batch_images)\n",
        "        predicted = (outputs.squeeze() > 0.5).int()\n",
        "        if predicted.dim() == 0:\n",
        "          predicted = predicted.unsqueeze(0)\n",
        "        predict_list = torch.cat((predict_list,predicted),0)\n",
        "\n",
        "\n",
        "predict_listq = predict_list.cpu()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s7klq4YR5Qg"
      },
      "outputs": [],
      "source": [
        "print_results(predict_listq, labels[:len(predict_list)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml59tSf2QXty"
      },
      "source": [
        "# 輸出至submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cont(l):\n",
        "  \"1是否連續\"\n",
        "  f1 = False\n",
        "  f2 = False\n",
        "  for i in range(len(l)):\n",
        "    if (l[i] == 1):\n",
        "      f1 = True\n",
        "    if (l[i] == 0):\n",
        "      if (f1):\n",
        "        f2 = True\n",
        "    if (l[i] == 1) and f2:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def yes(predict):\n",
        "  return int(sum(predict) >= 3)\n",
        "\n",
        "\n",
        "\n",
        "predict_list = predict_listq.numpy()\n",
        "\n",
        "## 還原id與對應label，假設key按照scan輸入順序排列,每個key對應的scan的cuts數是nslice\n",
        "output = {}\n",
        "k = 0  #第幾個scan\n",
        "ii = 0   #每個key輪到第幾個\n",
        "id, nslice = info[k][0], info[k][1]\n",
        "for i in range(len(predict_list)):\n",
        "\n",
        "  if (ii >= nslice):\n",
        "    #該換下一個scan了\n",
        "    output[id] = yes(predict_list[i-nslice:i]) #評估方式\n",
        "\n",
        "    k += 1\n",
        "    ii = 0\n",
        "    id, nslice = info[k][0], info[k][1]\n",
        "\n",
        "  label = predict_list[i]\n",
        "  output[id+f'_{ii}'] = int(predict_list[i])\n",
        "  ii += 1\n",
        "\n",
        "output[id] = yes(predict_list[(i+1)-ii:]) #補上最後一個scan評估\n",
        "# import pdb\n",
        "# pdb.set_trace()\n",
        "output = list(output.items())\n",
        "dfout = pd.DataFrame(output)\n",
        "dfout.columns = ['id', 'label']\n",
        "dfout = dfout.sort_values(by='id', key=lambda x: x.map(custom_sort_key))\n",
        "filename = input(\"輸入提交檔名(enter for submission)\")\n",
        "if filename == '':\n",
        "  filename = 'submission'\n",
        "dfout.to_csv(filename+'.csv', index=False)"
      ],
      "metadata": {
        "id": "eGcPvyce5uDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "id": "T2eaN23dXgfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhDYVsGNxVTZ"
      },
      "outputs": [],
      "source": [
        "dfout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 其他"
      ],
      "metadata": {
        "id": "wKe-NfBAeN8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "lC6LJpkZr4xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看submission files"
      ],
      "metadata": {
        "id": "Cm3O7vG7eP0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dftest = read_submission('fisrt_80.csv')\n",
        "# dftest = read_submission('submission.csv')\n",
        "dflabel = read_label(\"TrainValid_ground_truth.csv\")"
      ],
      "metadata": {
        "id": "oDM_yM-5bdCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dftest)"
      ],
      "metadata": {
        "id": "fRSaPgTBnbE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# 抓出scan-level data\n",
        "pattern = re.compile(r'.*_[0-9]+$')  # 正則表達式匹配 \"_數字\" 結尾\n",
        "mask = ~dftest.index.str.match(pattern)\n",
        "scan_guess = np.array(dftest[mask]['label'])\n",
        "scan_truth = np.array(dflabel.loc[dftest[mask]['label'].index]['label'])\n",
        "\n",
        "mask = ~mask\n",
        "cut_guess = np.array(dftest[mask]['label'])\n",
        "cut_truth = np.array(dflabel.loc[dftest[mask]['label'].index]['label'])"
      ],
      "metadata": {
        "id": "BD1NfxWTb2iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 10\n",
        "print(\"=\"*ss + \"F1 score on scan level\" + \"=\"*ss)\n",
        "print_results(scan_guess, scan_truth)\n",
        "print(),print()\n",
        "print(\"=\"*ss + \"F1 score on cut level\" +\"=\"*ss )\n",
        "print_results(cut_guess, cut_truth)"
      ],
      "metadata": {
        "id": "fyMlAtUWuW8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 其他指令\n",
        "不在工作流\n",
        "當參考"
      ],
      "metadata": {
        "id": "FG2tqJ1kMhzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "datadir = 'Train_Valid_Image'\n",
        "for idx, afile in enumerate(os.listdir(datadir)):\n",
        "  file_path = os.path.join(datadir, afile)\n",
        "  time.sleep(1)\n",
        "  nii_file =  nib.load(file_path)\n",
        "  print(f\"{idx}: read {afile}\")"
      ],
      "metadata": {
        "id": "eazF7afOHa8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'.*_[0-9]+$')  # 正則表達式匹配 \"_數字\" 結尾\n",
        "mask = dftest.index.to_series().str.match(pattern)\n",
        "dflabel_ = dftest[mask]\n",
        "dflabel_.index.map(lambda x : x.split('_')[1]).sort_values()[-3:]"
      ],
      "metadata": {
        "id": "lEForON9S9qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 假設這是您的列表\n",
        "my_list = np.array([1, 2, 3, 4])\n",
        "\n",
        "mask = [True, False, False, True]\n",
        "my_list[mask]"
      ],
      "metadata": {
        "id": "37C0pWRQTCyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datadir =\"TrainValid_Image/train_data\"\n",
        "labelpath = 'TrainValid_ground_truth.csv'\n",
        "labels_ = read_label(labelpath)\n",
        "\n",
        "\n",
        "filelist = os.listdir(datadir)\n",
        "filelist = filelist[10:20]\n",
        "selecteds = [labels_.loc[labels_.index.str.startswith(afile.strip('.nii')+'_')] for afile in filelist]\n",
        "scans_info = []\n",
        "# preallocated\n",
        "print(\"enter\")\n",
        "numcuts = [len(selected) for selected in selecteds]\n",
        "numcut = sum(numcuts)"
      ],
      "metadata": {
        "id": "el4YgUCT6LgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numcuts = [len(selected) for selected in selecteds]"
      ],
      "metadata": {
        "id": "TBvrMIwo6nhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = nib.load('Train_Valid_Image/Zx00AD16F8B97A53DE6E7CFE260BDF122F0E655659A3DF1628.nii.gz')\n"
      ],
      "metadata": {
        "id": "E9rP7qJsIFZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "RFBfoC3iMo1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RpwX2ZFOBRFT",
        "0IX5HYZuSKG-",
        "rhLO9PaUESQh"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}