{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guo-bot-1998/Appendicitis/blob/master/Appendicitis_colab_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coYrDLBnCbwQ"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q4kBLfXWRg7N",
        "outputId": "2d621dfb-2574-4f1e-ba1c-97cdb23b3251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m1.6/2.2 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting kora\n",
            "  Downloading kora-0.9.20-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kora) (7.34.0)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from kora) (1.5.29)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore->kora) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->kora) (23.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->kora)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kora) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kora) (0.2.12)\n",
            "Installing collected packages: jedi, kora\n",
            "Successfully installed jedi-0.19.1 kora-0.9.20\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install tqdm\n",
        "!pip install kora\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bQ4w8h2LkY0g"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import re\n",
        "import json\n",
        "import tqdm\n",
        "import timm\n",
        "import gdown\n",
        "from kora.xattr import get_id\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 存取"
      ],
      "metadata": {
        "id": "Oc3DYvY3WsL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_data2(shift=0, termi=10, dropFalse=0.85, dropPos=0)\\\n",
        " -> tuple[torch.tensor, torch.tensor, list[tuple[str, int]]]:\n",
        "  \"\"\"Reading data in \"datadir\" and process them.\n",
        "  Taking care of memory efficiency\"\n",
        "\n",
        "  Args:\n",
        "    shift: 從第幾個開始讀取\n",
        "    termi: 讀取幾個\n",
        "    dropFalse: 被刪除的有闌尾炎的張數比例\n",
        "    dropPos: 被刪除的有闌尾炎的張數比例\n",
        "\n",
        "  Returns:\n",
        "    images: 输出的图像数据\n",
        "    labels: 输出的标签数据\n",
        "    scans_info: 每個scan的檔名和切片數\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  labels_ = read_label(labelpath)\n",
        "\n",
        "  if labels_.index.name != 'id':\n",
        "    labels_.set_index('id', inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "  filelist = os.listdir(datadir)\n",
        "  filelist = filelist[shift:shift+termi]\n",
        "  selecteds = [labels_.loc[labels_.index.str.startswith(afile.strip('.nii.gz')+'_')] for afile in filelist]\n",
        "  scans_info = []\n",
        "  # preallocated\n",
        "  numcuts = [len(selected) for selected in selecteds]\n",
        "  images = torch.zeros((sum(numcuts),1, 512,512))\n",
        "  labels = -torch.ones((sum(numcuts)))\n",
        "  nimgs = 0\n",
        "  nprocess = 0\n",
        "\n",
        "  debug = 0\n",
        "\n",
        "  for key in filelist:\n",
        "    file_path = os.path.join(datadir, key)\n",
        "    key = key.strip('.nii.gz')\n",
        "    scan  = labels_.loc[labels_.index.str.startswith(key+'_')]\n",
        "\n",
        "    value = nib.load(file_path).get_fdata()\n",
        "    scans_info.append((key, value.shape[2]))\n",
        "    label_t = torch.tensor(scan['label'])\n",
        "    image_t = torch.from_numpy(value).float().permute(2, 0, 1).unsqueeze(1)\n",
        "\n",
        "\n",
        "    if (image_t.shape[2] != 512 or image_t.shape[3] != 512):\n",
        "      image_t = cropping(image_t)\n",
        "    image_t, label_t = remove_false_images(image_t, label_t, dropFalse)\n",
        "    image_t, label_t = remove_positive_images(image_t, label_t, dropPos)\n",
        "\n",
        "    n_new = len(label_t)\n",
        "    images[nimgs:nimgs+n_new] = image_t\n",
        "    labels[nimgs:nimgs+n_new] = label_t\n",
        "    nimgs += len(label_t)\n",
        "    print(f\"Process {nprocess}: {key} finished...\")\n",
        "    nprocess += 1\n",
        "\n",
        "  print(f\"read {len(scans_info)} scans\")\n",
        "\n",
        "  return images, labels.float(), scans_info\n",
        "\n",
        "\n",
        "\n",
        "def save_model(model, modelname=\"\", dirname=\"\", root=os.path.realpath(\"/content/drive/MyDrive/AOCR2024/params\")):\n",
        "\n",
        "  if not model:\n",
        "    print(\"not given model\")\n",
        "    return\n",
        "\n",
        "  if not os.path.exists(root):\n",
        "    print(f\"{root} not exists!\")\n",
        "    return\n",
        "\n",
        "  print(f\"model will be saved under {root}\")\n",
        "\n",
        "  if not modelname:\n",
        "    modelname = input(\"請輸入模型儲存的檔名:\")\n",
        "  if not dirname:\n",
        "    dirname = input(\"請輸入模型儲存的資料夾:\")\n",
        "\n",
        "  filename = f\"{root}/{dirname}/{modelname}\"\n",
        "\n",
        "  if not os.path.exists(os.path.dirname(filename)):\n",
        "    os.mkdir(os.path.dirname(filename))\n",
        "\n",
        "  if os.path.isfile(filename+'.pth'):\n",
        "      print(f\"{filename}.pth exist.\")\n",
        "  else:\n",
        "      torch.save(model.state_dict(), f'{filename}.pth')\n",
        "\n",
        "  return filename\n",
        "\n",
        "\n",
        "\n",
        "def read_label(excel_path) -> pd.DataFrame:\n",
        "  \"\"\"Reads a csv file containing ground-truth.\n",
        "    The csv file should have two columns: 'id' and 'label'.\n",
        "  \"\"\"\n",
        "  with open(excel_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "    df.set_index('id', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def write_error(logpath, e, nprocess):\n",
        "  # with open(logpath, 'a') as f:\n",
        "    # f.write(f\"{nprocess:} error occured: {e}\\n\") ##! may stuck the program!!\n",
        "  print(f\"{nprocess:} error occured: {e}\\n\")\n",
        "\n",
        "\n",
        "def read_submission(excel_path) -> pd.DataFrame:\n",
        "  \"\"\"Reads a csv file containing submission file.\n",
        "    The csv file should follow the format given by Kaggle.\n",
        "  \"\"\"\n",
        "  with open(excel_path, 'r') as f:\n",
        "    df = pd.read_csv(f)\n",
        "    df.set_index('id', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KLs_ItZEW0F1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 列印結果"
      ],
      "metadata": {
        "id": "Fnggb7x7X8Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confusion(guess, truth):\n",
        "  right = guess == truth\n",
        "  wrong = np.logical_not(right)\n",
        "  TP = np.sum(np.logical_and(right, truth == np.ones(right.shape)))\n",
        "  TN = np.sum(np.logical_and(right, truth == np.zeros(right.shape)))\n",
        "  FN = np.sum(np.logical_and(wrong, truth == np.ones(wrong.shape)))\n",
        "  FP = np.sum(np.logical_and(wrong, truth == np.zeros(wrong.shape)))\n",
        "  return (TP,FP,FN,TN)\n",
        "\n",
        "\n",
        "\n",
        "def print_results(prediction, labels):\n",
        "  if torch.is_tensor(prediction):\n",
        "    prediction = prediction.cpu().numpy()\n",
        "  if torch.is_tensor(labels):\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "  TP,FP,FN,TN = get_confusion(prediction, labels)\n",
        "  print(f\"\\n\\\n",
        "      真實值\\n\\\n",
        "  預  +-----+-----+\\n\\\n",
        "  測| TP: {TP}| FP: {FP}|\\n\\\n",
        "  值| FN: {FN}| TN: {TN}|\\n\\\n",
        "      +-----+-----+ \\n\")\n",
        "\n",
        "  recall = TP/(TP + FN)\n",
        "  precision = TP/(TP + FP)\n",
        "  recall = 0 if np.isnan(recall) else recall.item()\n",
        "  precision = 0 if np.isnan(precision) else precision.item()\n",
        "  F1 = 0 if recall + precision == 0 else  (2*recall*precision/(recall+precision))\n",
        "\n",
        "  print(f\"{recall=}\\n{precision=}\\n{F1=}\\n\")"
      ],
      "metadata": {
        "id": "1gFEpWQ-X7nc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 數據處理\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UsmaGmRwWmxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def argumenting(images, labels, n=5):\n",
        "  \"\"\"\n",
        "  數據增強。\n",
        "  在images裡面把所有有闌尾炎的cut複製給定次數，並\n",
        "  插入回images的隨機位置裡面\n",
        "\n",
        "  Args:\n",
        "    images: 输入的图像数据\n",
        "    labels: 输入的标签数据\n",
        "    n: 每个样本複製多少次\n",
        "\n",
        "  Returns:\n",
        "    增強后的图像数据和标签数据\n",
        "  \"\"\"\n",
        "  where = (labels == True).nonzero(as_tuple=True)[0]\n",
        "  bad_images = images[where]\n",
        "\n",
        "  rep_imgs = bad_images.repeat(n, 1, 1, 1)\n",
        "  rep_labels = torch.ones(rep_imgs.shape[0], dtype=labels.dtype)\n",
        "\n",
        "  # import pdb\n",
        "  # pdb.set_trace()\n",
        "  # 隨機插入argumented圖片\n",
        "  nimg = images.shape[0]\n",
        "  rnd_pos = torch.randint(0, nimg, (rep_imgs.shape[0],))\n",
        "  images = torch.cat((images, rep_imgs), dim=0)\n",
        "  images = images[torch.argsort(torch.cat((torch.arange(nimg), rnd_pos)))]\n",
        "\n",
        "  # 對應對置插入標籤\n",
        "  labels = torch.cat((labels, rep_labels), dim=0)\n",
        "  labels = labels[torch.argsort(torch.cat((torch.arange(nimg), rnd_pos)))]\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "def remove_false_images(images, labels, ratio):\n",
        "    \"\"\"\n",
        "    隨機在images裡面移除一定比例的無闌尾炎cut\n",
        "\n",
        "    Args:\n",
        "      images: 输入的图像数据\n",
        "      labels: 输入的标签数据\n",
        "      ratio: 移除的比例\n",
        "\n",
        "    Returns:\n",
        "      移除后的图像数据和标签数据\n",
        "    \"\"\"\n",
        "    # 找出 labels == 0 的索引\n",
        "    where_false = (labels == 0).nonzero(as_tuple=True)[0]\n",
        "    mask = torch.ones(len(images), dtype=torch.bool)\n",
        "    indices_filter = torch.randperm(len(where_false))[:int(len(where_false)*ratio)]\n",
        "    mask[where_false[indices_filter]] = False\n",
        "    images = images[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def remove_positive_images(images, labels, ratio):\n",
        "    # 找出 labels == 1 的索引\n",
        "    where_positive = (labels == 1).nonzero(as_tuple=True)[0]\n",
        "    mask = torch.ones(len(images), dtype=torch.bool)\n",
        "    indices_filter = torch.randperm(len(where_positive))[:int(len(where_positive)*ratio)]\n",
        "    mask[where_positive[indices_filter]] = False\n",
        "    images = images[mask]\n",
        "    labels = labels[mask]\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "6nLNS0uRWl5X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 其他"
      ],
      "metadata": {
        "id": "BdwzEjFhbR4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7dmJYugUB_3w"
      },
      "outputs": [],
      "source": [
        "\n",
        "def count_zero(images):\n",
        "  count = 0\n",
        "  for image in images:\n",
        "    if not torch.any(image):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "def cropping(image):\n",
        "  if image.shape[2] != 512:\n",
        "    start = (image.shape[2] - 512) // 2\n",
        "    end = start + 512\n",
        "    image = image[:, :, start:end, :]\n",
        "\n",
        "  if image.shape[3] != 512:\n",
        "    start = (image.shape[3] - 512) // 2\n",
        "    end = start + 512\n",
        "    image = image[:, :, :, start:end]\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def custom_sort_key(val):\n",
        "    parts = val.split('_')\n",
        "    if len(parts) == 2 and parts[1].isdigit():\n",
        "        return (parts[0], int(parts[1]))\n",
        "    return (parts[0], -1)  # 使沒有_(數字)的id排最前面\n",
        "\n",
        "\n",
        "def isgpu():\n",
        "    \"\"\"檢查是否有 CUDA 支持的 GPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"GPU is available\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        # raise(\"GPU not available\")\n",
        "    return device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ud4x-GeICQxw"
      },
      "outputs": [],
      "source": [
        "device = isgpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV66iCZmCrBJ"
      },
      "source": [
        "# 掛載\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bKUXzQOdBRFQ",
        "outputId": "f941b879-d1d3-482c-ca48-707d36cda8c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "5qbhdYNrGRxf",
        "outputId": "436e7c62-e697-4c64-ac7c-0929e6cdafef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 資料下載"
      ],
      "metadata": {
        "id": "3OZg-WX2NgQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_rootdir = \"/content/drive/MyDrive/AOCR2024\"\n",
        "labelpath = '/content/drive/MyDrive/AOCR2024/TrainValid_ground_truth.csv'\n",
        "\n",
        "datadir =\"Train_Valid_Image\"\n",
        "if not os.path.exists('/content/' +datadir):\n",
        "  os.mkdir(datadir)\n"
      ],
      "metadata": {
        "id": "dzzWlsmwlPCZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_on_drive = os.listdir(drive_rootdir+'/'+datadir)\n",
        "files_in_localdir = os.listdir(f\"/content/{datadir}\")\n",
        "files_to_download = [f for f in files_on_drive if f not in files_in_localdir]\n",
        "files = [(filename, get_id(f'{drive_rootdir}/{datadir}/{filename}')) for filename in files_to_download]\n",
        "for idx, (name, id) in enumerate(files):\n",
        "  # url = f\"https://drive.google.com/uc?id={id}&confirm=t\"\n",
        "  # url = f\"https://drive.google.com/file/d/{id}/view?usp=drive_link\"\n",
        "  url = f\"https://drive.google.com/u/1/uc?id={id}&confirm=t\"\n",
        "  response = requests.get(url, allow_redirects=True)\n",
        "  if response.status_code == 200:\n",
        "      with open(f\"/content/{datadir}/{name}\", 'wb') as file:\n",
        "          file.write(response.content)\n",
        "      print(f\"{idx+1}/{len(files)}: {name}\")\n",
        "  else:\n",
        "      print(f\"Error: Unable to download file. Status code: {response.status_code}\")\n",
        "\n",
        "# files_on_drive = os.listdir(drive_rootdir+'/'+datadir)\n",
        "# files_in_localdir = os.listdir(f\"/content/{datadir}\")\n",
        "# files_to_download = [f for f in files_on_drive if f not in files_in_localdir]\n",
        "# files = [(filename, get_id(f'{drive_rootdir}/{datadir}/{filename}')) for filename in files_to_download]\n",
        "# for idx, (name, id) in enumerate(files):\n",
        "#   gdown.download(f\"https://drive.google.com/uc?id={id}&confirm=t\", output=f\"/content/{datadir}/{name}\", quiet=True, use_cookies=False)\n",
        "#   print(f\"{idx+1}/{len(files)}: {name}\")"
      ],
      "metadata": {
        "id": "RUZd5b8QlKRZ",
        "outputId": "3f0bfbeb-63b0-4a91-9ffe-a2a6e165e243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/995: Zx95F33E17F7F8218E9FA35FC3D79D8EB9E02019709C3A5EC2.nii.gz\n",
            "2/995: Zx34C115FB55D8474D6F19B61FC5388EE4CF710E60F31443C5.nii.gz\n",
            "3/995: Zx3D212F640E8BAB683711B0A2B808E94D20EC94C210350D4F.nii.gz\n",
            "4/995: Zx4343A182A4B16B07C4E9DC4CC327DCA2B2D54632240F5179.nii.gz\n",
            "5/995: ZxBCBA63BCCC1F7498AA92F4AF08511FFED09105BBFC63864E.nii.gz\n",
            "6/995: ZxBE2A252CBA88052F4A6B548249B9D70F14E4552A09EFAC38.nii.gz\n",
            "7/995: ZxEACFC663D819866E172E1DD2EC69EF67339C975F9A23A451.nii.gz\n",
            "8/995: ZxA587DD3F3B7DEFF324487D39123C2C626E291DCF7376E42D.nii.gz\n",
            "9/995: Zx2D43BBDA962A8DC656EF3C61E52CC75604BAD0E6AD08F938.nii.gz\n",
            "10/995: Zx1882493D839CC3171D0FEA7AE764BB5BC308D707E75CCB60.nii.gz\n",
            "11/995: ZxE379608F86D71DD9A2EE5FE1F9BCA94B1526AF3E1F5D036D.nii.gz\n",
            "12/995: Zx548829E2295B777477EEF5AD7B52516483F97FE03FFCD0EF.nii.gz\n",
            "13/995: Zx1A3FF9BBC87A0A6379CA804FA7025BE5E55D98B90E6E911E.nii.gz\n",
            "14/995: ZxD4CF37EF147DDEE980BAB4F5256CC86CA734F199E5512303.nii.gz\n",
            "15/995: Zx4A3A3EB7F67074DEA9C5668137108C5BDFFE5AD82B6C9968.nii.gz\n",
            "16/995: Zx57410A845E6E8D25823E485244B4E8F17DDFC08B2883A6BA.nii.gz\n",
            "17/995: Zx9D76C42817583BCA25AF1F14469B372700E105BFC7452D78.nii.gz\n",
            "18/995: Zx808CBF85580C8A52F625D7FC9667F12DA964A7194E5A900F.nii.gz\n",
            "19/995: Zx9FAE5E8EE578A076D0A2FB260477EAC119844611FEE70C48.nii.gz\n",
            "20/995: Zx55AD3019A3318C2BD693F2094679AD6751F86FF222B86674.nii.gz\n",
            "21/995: Zx29249C3340706D8A658BC96F288DE057693CDCA0C50018FF.nii.gz\n",
            "22/995: ZxC7F93D23D81997D7158951EDAAC448DE709828F562E63B5C.nii.gz\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b33ab525e2b4>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# url = f\"https://drive.google.com/file/d/{id}/view?usp=drive_link\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"https://drive.google.com/u/1/uc?id={id}&confirm=t\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/content/{datadir}/{name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m# Redirect resolving generator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_redirects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 resp = self.send(\n\u001b[0m\u001b[1;32m    267\u001b[0m                     \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(datadir)"
      ],
      "metadata": {
        "id": "xXH5tN8Jq4Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0ME8m8YBRFR"
      },
      "source": [
        "# 資料處理"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dflabel = read_label(labelpath)\n",
        "total_nii = len(os.listdir(datadir))\n",
        "images, labels, _ =  process_data2(termi=total_nii,shift=0,dropFalse=0,dropPos=0)"
      ],
      "metadata": {
        "id": "WFJpwdc4cSci",
        "outputId": "991f2d4e-23a3-45f2-df65-9e6d04f1e56b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0: Zx4A3A3EB7F67074DEA9C5668137108C5BDFFE5AD82B6C9968 finished...\n",
            "Process 1: Zx29249C3340706D8A658BC96F288DE057693CDCA0C50018FF finished...\n",
            "Process 2: Zx1A3FF9BBC87A0A6379CA804FA7025BE5E55D98B90E6E911E finished...\n",
            "Process 3: Zx30D3D7722571163D6FDAC8D42EA822DE9309AA749507E680 finished...\n",
            "Process 4: Zx57410A845E6E8D25823E485244B4E8F17DDFC08B2883A6BA finished...\n",
            "Process 5: Zx1950A84DEF7878F0F9E32AF9F820CA049C5880BA46C37601 finished...\n",
            "Process 6: Zx34C115FB55D8474D6F19B61FC5388EE4CF710E60F31443C5 finished...\n",
            "Process 7: ZxD8736DEB1A7AFA67733E095769BBD236FFAD5150198E5109 finished...\n",
            "Process 8: Zx95F33E17F7F8218E9FA35FC3D79D8EB9E02019709C3A5EC2 finished...\n",
            "Process 9: Zx4343A182A4B16B07C4E9DC4CC327DCA2B2D54632240F5179 finished...\n",
            "Process 10: Zx3D212F640E8BAB683711B0A2B808E94D20EC94C210350D4F finished...\n",
            "Process 11: ZxE379608F86D71DD9A2EE5FE1F9BCA94B1526AF3E1F5D036D finished...\n",
            "Process 12: Zx548829E2295B777477EEF5AD7B52516483F97FE03FFCD0EF finished...\n",
            "Process 13: Zx9FAE5E8EE578A076D0A2FB260477EAC119844611FEE70C48 finished...\n",
            "Process 14: Zx1060A72A4F5C5FFE63F395F263138C39C901CEA1B608B5D3 finished...\n",
            "Process 15: Zx808CBF85580C8A52F625D7FC9667F12DA964A7194E5A900F finished...\n",
            "Process 16: Zx1882493D839CC3171D0FEA7AE764BB5BC308D707E75CCB60 finished...\n",
            "Process 17: Zx55AD3019A3318C2BD693F2094679AD6751F86FF222B86674 finished...\n",
            "Process 18: Zx9D76C42817583BCA25AF1F14469B372700E105BFC7452D78 finished...\n",
            "Process 19: ZxD4CF37EF147DDEE980BAB4F5256CC86CA734F199E5512303 finished...\n",
            "Process 20: ZxA587DD3F3B7DEFF324487D39123C2C626E291DCF7376E42D finished...\n",
            "Process 21: ZxBE2A252CBA88052F4A6B548249B9D70F14E4552A09EFAC38 finished...\n",
            "Process 22: Zx29D944DDC12D73E641FD78628DA3CCDAD0CCD13F9C098056 finished...\n",
            "Process 23: ZxC7F93D23D81997D7158951EDAAC448DE709828F562E63B5C finished...\n",
            "Process 24: ZxEACFC663D819866E172E1DD2EC69EF67339C975F9A23A451 finished...\n",
            "Process 25: ZxBCBA63BCCC1F7498AA92F4AF08511FFED09105BBFC63864E finished...\n",
            "Process 26: Zx2D43BBDA962A8DC656EF3C61E52CC75604BAD0E6AD08F938 finished...\n",
            "read 27 scans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %reset_selective images"
      ],
      "metadata": {
        "id": "jeAD7ynnVOWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %reset"
      ],
      "metadata": {
        "id": "ZWaEl6uf0eLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IX5HYZuSKG-"
      },
      "source": [
        "# 訓練 (EfficiencyNetV2_m)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "PjcZY1-Oehib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"tf_efficientnetv2_m\"\n",
        "pretrained_model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "# 修改輸入通道\n",
        "pretrained_model.conv_stem = nn.Conv2d(1, 24, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "# 修改輸出類別\n",
        "num_classes = 1\n",
        "pretrained_model.classifier = nn.Linear(pretrained_model.classifier.in_features, num_classes)\n",
        "\n",
        "# 添加 Sigmoid 激活函數\n",
        "pretrained_model = nn.Sequential(\n",
        "    pretrained_model,\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# 檢查模型結構\n",
        "# print(pretrained_model)\n"
      ],
      "metadata": {
        "id": "jZ0cSVS51BHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def between_epoch():\n",
        "  del images, labels\n",
        "  images, labels, _ = process_data2(termi=total_nii, shift=0,dropFalse=0.8,dropPos=0)\n",
        "  dataset = CustomDataset(images, labels)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "Ykire39uf_n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdKCQjs_Ozum"
      },
      "outputs": [],
      "source": [
        "# 訓練參數\n",
        "num_epochs = 10\n",
        "batch_size = 8\n",
        "lr = 0.01\n",
        "running_loss_list = []\n",
        "\n",
        "# 初始化模型、損失函數和優化器\n",
        "model = pretrained_model\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "model = model.to(device)\n",
        "\n",
        "dataset = CustomDataset(images, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for batch_images, batch_labels in dataloader:\n",
        "        batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_images)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    dataloader = between_epoch()\n",
        "\n",
        "    running_loss_list.append(running_loss/len(dataloader))\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhLO9PaUESQh"
      },
      "source": [
        "## Loss圖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvRouRxFEXy2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(1,num_epochs+1)[:len(running_loss_list)], running_loss_list)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRrn6mOmBRFU"
      },
      "source": [
        "# 儲存模型參數\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jnh7hW3BRFU"
      },
      "outputs": [],
      "source": [
        "filename = save_model(model)\n",
        "\n",
        "params = {\n",
        "    'num_epochs': num_epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': lr,\n",
        "}\n",
        "\n",
        "if os.path.isfile(filename+'.json'):\n",
        "    print(f\"{filename}.json exist.\")\n",
        "else:\n",
        "    with open(f'{filename}.json', 'w') as f:\n",
        "        json.dump(params, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBcppdev6LlG"
      },
      "source": [
        "# 讀取模型參數"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = pretrained_model\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "id": "Pfx0VwbRN9uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NUlm7dg5sRE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "filename = input(\"請輸入要獲取模型路徑:\")\n",
        "\n",
        "if not os.path.isfile(filename+'.pth'):\n",
        "    print(f\"{filename}.pth not exist.\")\n",
        "else:\n",
        "    print(model.load_state_dict(torch.load(filename+'.pth')))\n",
        "\n",
        "with open(f'{filename}.json', 'r') as f:\n",
        "    params = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v_lVRL47kzj"
      },
      "source": [
        "# 評估\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data(\"TrainValid_Image/train_data\",termi=80,shift=80)\n",
        "# data = read_data(\"Test1_Image/test_data\",termi=3,shift=1)\n",
        "dflabel = read_label(\"TrainValid_ground_truth.csv\")"
      ],
      "metadata": {
        "id": "uLNoNdr155p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels,info = process_data(data, dflabel)"
      ],
      "metadata": {
        "id": "4ZfJbfii6FFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtWJ-YYy5l2E"
      },
      "outputs": [],
      "source": [
        "# 評估設置\n",
        "num_epochs = params['num_epochs']\n",
        "batch_size = params['batch_size']\n",
        "\n",
        "#最後data不滿一個batch\n",
        "num_batches = len(images) // batch_size\n",
        "if len(images) % batch_size != 0:\n",
        "  num_batches += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M1qST-FslSs"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "predict_list = torch.tensor([]).to(device)\n",
        "with torch.no_grad():  # 不更新梯度\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in range(num_batches):\n",
        "        batch_images = images[i*batch_size:(i+1)*batch_size].to(device)\n",
        "        batch_labels = labels[i*batch_size:(i+1)*batch_size].to(device)\n",
        "\n",
        "        outputs = model(batch_images)\n",
        "        predicted = (outputs.squeeze() > 0.5).int()\n",
        "        if predicted.dim() == 0:\n",
        "          predicted = predicted.unsqueeze(0)\n",
        "        predict_list = torch.cat((predict_list,predicted),0)\n",
        "\n",
        "\n",
        "predict_listq = predict_list.cpu()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s7klq4YR5Qg"
      },
      "outputs": [],
      "source": [
        "print_results(predict_listq, labels[:len(predict_list)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml59tSf2QXty"
      },
      "source": [
        "# 輸出至submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cont(l):\n",
        "  \"1是否連續\"\n",
        "  f1 = False\n",
        "  f2 = False\n",
        "  for i in range(len(l)):\n",
        "    if (l[i] == 1):\n",
        "      f1 = True\n",
        "    if (l[i] == 0):\n",
        "      if (f1):\n",
        "        f2 = True\n",
        "    if (l[i] == 1) and f2:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def yes(predict):\n",
        "  return int(sum(predict) >= 3)\n",
        "\n",
        "\n",
        "\n",
        "predict_list = predict_listq.numpy()\n",
        "\n",
        "## 還原id與對應label，假設key按照scan輸入順序排列,每個key對應的scan的cuts數是nslice\n",
        "output = {}\n",
        "k = 0  #第幾個scan\n",
        "ii = 0   #每個key輪到第幾個\n",
        "id, nslice = info[k][0], info[k][1]\n",
        "for i in range(len(predict_list)):\n",
        "\n",
        "  if (ii >= nslice):\n",
        "    #該換下一個scan了\n",
        "    output[id] = yes(predict_list[i-nslice:i]) #評估方式\n",
        "\n",
        "    k += 1\n",
        "    ii = 0\n",
        "    id, nslice = info[k][0], info[k][1]\n",
        "\n",
        "  label = predict_list[i]\n",
        "  output[id+f'_{ii}'] = int(predict_list[i])\n",
        "  ii += 1\n",
        "\n",
        "output[id] = yes(predict_list[(i+1)-ii:]) #補上最後一個scan評估\n",
        "# import pdb\n",
        "# pdb.set_trace()\n",
        "output = list(output.items())\n",
        "dfout = pd.DataFrame(output)\n",
        "dfout.columns = ['id', 'label']\n",
        "dfout = dfout.sort_values(by='id', key=lambda x: x.map(custom_sort_key))\n",
        "filename = input(\"輸入提交檔名(enter for submission)\")\n",
        "if filename == '':\n",
        "  filename = 'submission'\n",
        "dfout.to_csv(filename+'.csv', index=False)"
      ],
      "metadata": {
        "id": "eGcPvyce5uDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "id": "T2eaN23dXgfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhDYVsGNxVTZ"
      },
      "outputs": [],
      "source": [
        "dfout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 查看submission.csv"
      ],
      "metadata": {
        "id": "wKe-NfBAeN8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "lC6LJpkZr4xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dftest = read_submission('fisrt_80.csv')\n",
        "# dftest = read_submission('submission.csv')\n",
        "dflabel = read_label(\"TrainValid_ground_truth.csv\")"
      ],
      "metadata": {
        "id": "oDM_yM-5bdCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dftest)"
      ],
      "metadata": {
        "id": "fRSaPgTBnbE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# 抓出scan-level data\n",
        "pattern = re.compile(r'.*_[0-9]+$')  # 正則表達式匹配 \"_數字\" 結尾\n",
        "mask = ~dftest.index.str.match(pattern)\n",
        "scan_guess = np.array(dftest[mask]['label'])\n",
        "scan_truth = np.array(dflabel.loc[dftest[mask]['label'].index]['label'])\n",
        "\n",
        "mask = ~mask\n",
        "cut_guess = np.array(dftest[mask]['label'])\n",
        "cut_truth = np.array(dflabel.loc[dftest[mask]['label'].index]['label'])"
      ],
      "metadata": {
        "id": "BD1NfxWTb2iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = 10\n",
        "print(\"=\"*ss + \"F1 score on scan level\" + \"=\"*ss)\n",
        "print_results(scan_guess, scan_truth)\n",
        "print(),print()\n",
        "print(\"=\"*ss + \"F1 score on cut level\" +\"=\"*ss )\n",
        "print_results(cut_guess, cut_truth)"
      ],
      "metadata": {
        "id": "fyMlAtUWuW8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 其他指令\n",
        "不在工作流\n",
        "當參考"
      ],
      "metadata": {
        "id": "FG2tqJ1kMhzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "datadir = 'Train_Valid_Image'\n",
        "for idx, afile in enumerate(os.listdir(datadir)):\n",
        "  file_path = os.path.join(datadir, afile)\n",
        "  time.sleep(1)\n",
        "  nii_file =  nib.load(file_path)\n",
        "  print(f\"{idx}: read {afile}\")"
      ],
      "metadata": {
        "id": "eazF7afOHa8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r'.*_[0-9]+$')  # 正則表達式匹配 \"_數字\" 結尾\n",
        "mask = dftest.index.to_series().str.match(pattern)\n",
        "dflabel_ = dftest[mask]\n",
        "dflabel_.index.map(lambda x : x.split('_')[1]).sort_values()[-3:]"
      ],
      "metadata": {
        "id": "lEForON9S9qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 假設這是您的列表\n",
        "my_list = np.array([1, 2, 3, 4])\n",
        "\n",
        "mask = [True, False, False, True]\n",
        "my_list[mask]"
      ],
      "metadata": {
        "id": "37C0pWRQTCyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datadir =\"TrainValid_Image/train_data\"\n",
        "labelpath = 'TrainValid_ground_truth.csv'\n",
        "labels_ = read_label(labelpath)\n",
        "\n",
        "\n",
        "filelist = os.listdir(datadir)\n",
        "filelist = filelist[10:20]\n",
        "selecteds = [labels_.loc[labels_.index.str.startswith(afile.strip('.nii')+'_')] for afile in filelist]\n",
        "scans_info = []\n",
        "# preallocated\n",
        "print(\"enter\")\n",
        "numcuts = [len(selected) for selected in selecteds]\n",
        "numcut = sum(numcuts)"
      ],
      "metadata": {
        "id": "el4YgUCT6LgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numcuts = [len(selected) for selected in selecteds]"
      ],
      "metadata": {
        "id": "TBvrMIwo6nhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = nib.load('Train_Valid_Image/Zx00AD16F8B97A53DE6E7CFE260BDF122F0E655659A3DF1628.nii.gz')\n"
      ],
      "metadata": {
        "id": "E9rP7qJsIFZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "RFBfoC3iMo1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.randint(3,(5,1,2,2))\n",
        "lab = torch.tensor([1,1,1,1,1])\n",
        "t1"
      ],
      "metadata": {
        "id": "v3E6Q2z4R6-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_positive_images(t1,lab,0.79)"
      ],
      "metadata": {
        "id": "vMKO8czxSMd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown gdown"
      ],
      "metadata": {
        "id": "-WWE6jOKCD0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "v57WjC4VAtaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/1C7HXpHMw1Alvwif9hO97FUzfn4rhxG8B -O Train_Valid_Image --folder --remaining-ok"
      ],
      "metadata": {
        "id": "1T5_yrOg7RLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RpwX2ZFOBRFT",
        "0IX5HYZuSKG-",
        "rhLO9PaUESQh"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}